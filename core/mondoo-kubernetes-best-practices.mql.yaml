owner_mrn: //policy.api.mondoo.app
policies:
- uid: mondoo-kubernetes-best-practices
  name: Kubernetes Best Practices by Mondoo
  version: 1.0.0
  is_public: true
  authors:
    - name: Mondoo, Inc
      email: hello@mondoo.com
  docs:
    desc: |-
      The Kubernetes Best Practices by Mondoo policy bundle provides guidance for establishing reliable Kubernetes clusters by encouraging the adoption of best practices.
 
      If you have questions, comments, or have identified ways to improve this policy, please write us at hello@mondoo.com, or reach out in [GitHub Discussions](https://github.com/orgs/mondoohq/discussions).
  scoring_system: 2
  specs:
  - asset_filter:
      query: platform.name == "k8s-cronjob"
    scoring_queries:
      mondoo-kubernetes-best-practices-cronjob-requestcpu:
      mondoo-kubernetes-best-practices-cronjob-requestmemory:
      mondoo-kubernetes-best-practices-cronjob-livenessprobe:
      mondoo-kubernetes-best-practices-cronjob-readinessProbe:
      mondoo-kubernetes-best-practices-cronjob-hostalias:
      mondoo-kubernetes-best-practices-cronjob-default-namespace:
      mondoo-kubernetes-best-practices-cronjob-ports-hostport:
    data_queries:
  - asset_filter:
      query: platform.name == "k8s-statefulset"
    scoring_queries:
      mondoo-kubernetes-best-practices-statefulset-requestcpu:
      mondoo-kubernetes-best-practices-statefulset-requestmemory:
      mondoo-kubernetes-best-practices-statefulset-livenessprobe:
      mondoo-kubernetes-best-practices-statefulset-readinessProbe:
      mondoo-kubernetes-best-practices-statefulset-hostalias:
      mondoo-kubernetes-best-practices-statefulset-default-namespace:
      mondoo-kubernetes-best-practices-statefulset-ports-hostport:
    data_queries:
  - asset_filter:
      query: platform.name == "k8s-deployment"
    scoring_queries:
      mondoo-kubernetes-best-practices-deployment-requestcpu:
      mondoo-kubernetes-best-practices-deployment-requestmemory:
      mondoo-kubernetes-best-practices-deployment-livenessprobe:
      mondoo-kubernetes-best-practices-deployment-readinessProbe:
      mondoo-kubernetes-best-practices-deployment-hostalias:
      mondoo-kubernetes-best-practices-deployment-default-namespace:
      mondoo-kubernetes-best-practices-deployment-ports-hostport:
    data_queries:
  - asset_filter:
      query: platform.name == "k8s-job"
    scoring_queries:
      mondoo-kubernetes-best-practices-job-requestcpu:
      mondoo-kubernetes-best-practices-job-requestmemory:
      mondoo-kubernetes-best-practices-job-livenessprobe:
      mondoo-kubernetes-best-practices-job-readinessProbe:
      mondoo-kubernetes-best-practices-job-hostalias:
      mondoo-kubernetes-best-practices-job-default-namespace:
      mondoo-kubernetes-best-practices-job-ports-hostport:
    data_queries:
  - asset_filter:
      query: platform.name == "k8s-replicaset"
    scoring_queries:
      mondoo-kubernetes-best-practices-replicaset-requestcpu:
      mondoo-kubernetes-best-practices-replicaset-requestmemory:
      mondoo-kubernetes-best-practices-replicaset-livenessprobe:
      mondoo-kubernetes-best-practices-replicaset-readinessProbe:
      mondoo-kubernetes-best-practices-replicaset-hostalias:
      mondoo-kubernetes-best-practices-replicaset-default-namespace:
      mondoo-kubernetes-best-practices-replicaset-ports-hostport:
    data_queries:
  - asset_filter:
      query: platform.name == "k8s-daemonset"
    scoring_queries:
      mondoo-kubernetes-best-practices-daemonset-requestcpu:
      mondoo-kubernetes-best-practices-daemonset-requestmemory:
      mondoo-kubernetes-best-practices-daemonset-livenessprobe:
      mondoo-kubernetes-best-practices-daemonset-readinessProbe:
      mondoo-kubernetes-best-practices-daemonset-hostalias:
      mondoo-kubernetes-best-practices-daemonset-default-namespace:
      mondoo-kubernetes-best-practices-daemonset-ports-hostport:
    data_queries:
  - asset_filter:
      query: platform.name == "k8s-pod"
    scoring_queries:
      mondoo-kubernetes-best-practices-pod-requestcpu:
      mondoo-kubernetes-best-practices-pod-requestmemory:
      mondoo-kubernetes-best-practices-pod-livenessprobe:
      mondoo-kubernetes-best-practices-pod-readinessProbe:
      mondoo-kubernetes-best-practices-pod-hostalias:
      mondoo-kubernetes-best-practices-pod-no-owner:
      mondoo-kubernetes-best-practices-pod-default-namespace:
      mondoo-kubernetes-best-practices-pod-ports-hostport:
    data_queries:
      # mondoo-kubernetes-best-practices-gather-pods-security-context:
      # mondoo-kubernetes-best-practices-gather-deployment-container:
      # mondoo-kubernetes-best-practices-gather-daemonset-container:
      # mondoo-kubernetes-best-practices-gather-statefulset-container:
      # mondoo-kubernetes-best-practices-gather-job-container:
      # mondoo-kubernetes-best-practices-gather-cronjob-container:
queries:
- uid: mondoo-kubernetes-best-practices-pod-no-owner
  title: Pods should have an owner
  severity: 50
  docs:
    desc: |
      Pods without an owner (ie ReplicaSet, Job, etc.) will not be automatically restarted in the event of a Pod crash or Node failure.
    audit: |
      Check for Pods without an owner reference. Any line of output starting with '0' will indicate a Pod that has no owner:

      ```kubectl get pods -A -o json | jq -r '.items[] | [(.metadata.ownerReferences | length), .metadata.namespace, .metadata.name] | @tsv'```
    remediation: |
      For each Pod without an owner, ensure the Pod is owned by an appropriate Kubernetes object (eg Deployment, Job, DaemonSet, etc.) that will manage relaunching the Pod in the event of a failure.
  query: |
    # @msg Pod ${ _.name } should be managed by an appropriate Kubernetes object (eg Deployment, Job, DaemonSet, etc.)
    k8s.pod {
      manifest['metadata']['ownerReferences'] != null && manifest['metadata']['ownerReferences'].length > 0
    }
- uid: mondoo-kubernetes-best-practices-pod-requestcpu
  title: Container should request CPU
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much CPU a container needs.
    audit: |
      Check for the existence of CPU `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
    remediation: |
      Define the required resources for CPU `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
  refs:
    - title: Resource Management for Pods and Containers
      url: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  query: |
    k8s.pod {
      initContainers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-cronjob-requestcpu
  title: Container should request CPU
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much CPU a container needs.
    audit: |
      Check for the existence of CPU `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
    remediation: |
      Define the required resources for CPU `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
  refs:
    - title: Resource Management for Pods and Containers
      url: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  query: |
    k8s.cronjob {
      initContainers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-statefulset-requestcpu
  title: Container should request CPU
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much CPU a container needs.
    audit: |
      Check for the existence of CPU `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
    remediation: |
      Define the required resources for CPU `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
  refs:
    - title: Resource Management for Pods and Containers
      url: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  query: |
    k8s.statefulset {
      initContainers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-deployment-requestcpu
  title: Container should request CPU
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much CPU a container needs.
    audit: |
      Check for the existence of CPU `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
    remediation: |
      Define the required resources for CPU `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
  refs:
    - title: Resource Management for Pods and Containers
      url: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  query: |
    k8s.deployment {
      initContainers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-job-requestcpu
  title: Container should request CPU
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much CPU a container needs.
    audit: |
      Check for the existence of CPU `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
    remediation: |
      Define the required resources for CPU `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
  refs:
    - title: Resource Management for Pods and Containers
      url: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  query: |
    k8s.job {
      initContainers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-replicaset-requestcpu
  title: Container should request CPU
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much CPU a container needs.
    audit: |
      Check for the existence of CPU `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
    remediation: |
      Define the required resources for CPU `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
  refs:
    - title: Resource Management for Pods and Containers
      url: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  query: |
    k8s.replicaset {
      initContainers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-daemonset-requestcpu
  title: Container should request CPU
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much CPU a container needs.
    audit: |
      Check for the existence of CPU `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
    remediation: |
      Define the required resources for CPU `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                cpu: "250m"
      ```
  refs:
    - title: Resource Management for Pods and Containers
      url: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  query: |
    k8s.daemonset {
      initContainers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set CPU requests
        resources['requests']['cpu'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-pod-requestmemory
  title: Container should request memory
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much memory a container needs.
    audit: |
      Check for the existence of memory `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
    remediation: |
      Define the required resources for memory `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
  query: |
    k8s.pod { 
      initContainers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
      containers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-cronjob-requestmemory
  title: Container should request memory
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much memory a container needs.
    audit: |
      Check for the existence of memory `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
    remediation: |
      Define the required resources for memory `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
  query: |
    k8s.cronjob {
      initContainers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
      containers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-statefulset-requestmemory
  title: Container should request memory
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much memory a container needs.
    audit: |
      Check for the existence of memory `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
    remediation: |
      Define the required resources for memory `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
  query: |
    k8s.statefulset {
      initContainers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
      containers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-deployment-requestmemory
  title: Container should request memory
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much memory a container needs.
    audit: |
      Check for the existence of memory `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
    remediation: |
      Define the required resources for memory `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
  query: |
    k8s.deployment {
      initContainers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
      containers {
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-job-requestmemory
  title: Container should request memory
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much memory a container needs.
    audit: |
      Check for the existence of memory `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
    remediation: |
      Define the required resources for memory `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
  query: |
    k8s.job {
      initContainers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
      containers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-replicaset-requestmemory
  title: Container should request memory
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much memory a container needs.
    audit: |
      Check for the existence of memory `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
    remediation: |
      Define the required resources for memory `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
  query: |
    k8s.replicaset {
      initContainers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
      containers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-daemonset-requestmemory
  title: Container should request memory
  severity: 20
  docs:
    desc: |
      When defining a Pod, you should specify how much memory a container needs.
    audit: |
      Check for the existence of memory `requests` resources.
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
    remediation: |
      Define the required resources for memory `requests` in the container spec: 
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: app
            image: images.my-company.example/app:v1
            resources:
              requests:
                memory: "1Gi"
      ```
  query: |
    k8s.daemonset { 
      initContainers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
      containers { 
        # @msg Container ${ _.name  } should set memory requests
        resources['requests']['memory'] != null
      }
    }
- uid: mondoo-kubernetes-best-practices-pod-livenessprobe
  title: Container should configure a livenessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `livenessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            livenessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.pod {
      containers { 
        probeSpecified = livenessProbe['httpGet'] != null || livenessProbe['tcpSocket'] != null || livenessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a livenessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-cronjob-livenessprobe
  title: Container should configure a livenessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `livenessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            livenessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.cronjob {
      containers { 
        probeSpecified = livenessProbe['httpGet'] != null || livenessProbe['tcpSocket'] != null || livenessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a livenessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-statefulset-livenessprobe
  title: Container should configure a livenessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `livenessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            livenessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.statefulset {
      containers { 
        probeSpecified = livenessProbe['httpGet'] != null || livenessProbe['tcpSocket'] != null || livenessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a livenessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-deployment-livenessprobe
  title: Container should configure a livenessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `livenessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            livenessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.deployment {
      containers {
        probeSpecified = livenessProbe['httpGet'] != null || livenessProbe['tcpSocket'] != null || livenessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a livenessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-job-livenessprobe
  title: Container should configure a livenessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `livenessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            livenessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.job {
      containers { 
        probeSpecified = livenessProbe['httpGet'] != null || livenessProbe['tcpSocket'] != null || livenessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a livenessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-replicaset-livenessprobe
  title: Container should configure a livenessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `livenessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            livenessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.replicaset {
      containers { 
        probeSpecified = livenessProbe['httpGet'] != null || livenessProbe['tcpSocket'] != null || livenessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a livenessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-daemonset-livenessprobe
  title: Container should configure a livenessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `livenessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            livenessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.daemonset {
      containers { 
        probeSpecified = livenessProbe['httpGet'] != null || livenessProbe['tcpSocket'] != null || livenessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a livenessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-pod-readinessProbe
  title: Container should configure a readinessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `readinessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            readinessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.pod {
      containers { 
        probeSpecified = readinessProbe['httpGet'] != null || readinessProbe['tcpSocket'] != null || readinessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a readinessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-cronjob-readinessProbe
  title: Container should configure a readinessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `readinessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            readinessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.cronjob {
      containers { 
        probeSpecified = readinessProbe['httpGet'] != null || readinessProbe['tcpSocket'] != null || readinessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a readinessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-statefulset-readinessProbe
  title: Container should configure a readinessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `readinessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            readinessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.statefulset {
      containers { 
        probeSpecified = readinessProbe['httpGet'] != null || readinessProbe['tcpSocket'] != null || readinessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a readinessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-deployment-readinessProbe
  title: Container should configure a readinessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `readinessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            readinessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.deployment {
      containers {
        probeSpecified = readinessProbe['httpGet'] != null || readinessProbe['tcpSocket'] != null || readinessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a readinessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-job-readinessProbe
  title: Container should configure a readinessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `readinessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            readinessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.job {
      containers { 
        probeSpecified = readinessProbe['httpGet'] != null || readinessProbe['tcpSocket'] != null || readinessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a readinessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-replicaset-readinessProbe
  title: Container should configure a readinessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `readinessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            readinessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.replicaset {
      containers { 
        probeSpecified = readinessProbe['httpGet'] != null || readinessProbe['tcpSocket'] != null || readinessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a readinessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-daemonset-readinessProbe
  title: Container should configure a readinessProbe
  severity: 20
  docs:
    audit: |
      Check for the existence of `readinessProbe`:
      
      ```yaml
      ---
      apiVersion: v1
      kind: Pod
      spec:
        containers:
          - name: container-name
            image: index.docker.io/yournamespace/repository
            readinessProbe:
              tcpSocket:
                port: 8080
              initialDelaySeconds: 5
              periodSeconds: 5
      ```
  query: |
    k8s.daemonset {
      containers { 
        probeSpecified = readinessProbe['httpGet'] != null || readinessProbe['tcpSocket'] != null || readinessProbe['exec'] != null

        # @msg Container ${ _.name  } should set a readinessProbe
        probeSpecified == true
      }
    }
- uid: mondoo-kubernetes-best-practices-pod-hostalias
  title: Pod should not define hostAliases
  docs:
    desc: |
      DNS entries shouldn't be managed locally via `/etc/hosts` within pods. This can result in unintended and/or dangerous outcomes.
    audit: |
      Check for the existence of `hostAliases` setting in `spec`:

      ```yaml
      apiVersion: v1
      kind: Pod
      spec:
        hostAliases:
          - ip: "127.0.0.1"
            hostnames:
              - "foo.local"
              - "bar.local"
        containers:
          - name: example-app
            image: index.docker.io/yournamespace/repository
      ```
  refs:
    - title: Adding entries to Pod /etc/hosts with HostAliases
      url: https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
  query: |
    k8s.pod {
      podSpec['hostAliases'] == null
    }
- uid: mondoo-kubernetes-best-practices-cronjob-hostalias
  title: Pod should not define hostAliases
  docs:
    desc: |
      DNS entries shouldn't be managed locally via `/etc/hosts` within pods. This can result in unintended and/or dangerous outcomes.
    audit: |
      Check for the existence of `hostAliases` setting in `spec`:

      ```yaml
      apiVersion: v1
      kind: Pod
      spec:
        hostAliases:
          - ip: "127.0.0.1"
            hostnames:
              - "foo.local"
              - "bar.local"
        containers:
          - name: example-app
            image: index.docker.io/yournamespace/repository
      ```
  refs:
    - title: Adding entries to Pod /etc/hosts with HostAliases
      url: https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
  query: |
    k8s.cronjob {
      manifest['spec']['jobTemplate']['spec']['template']['spec']['hostAliases'] == null
    }
- uid: mondoo-kubernetes-best-practices-statefulset-hostalias
  title: Pod should not define hostAliases
  docs:
    desc: |
      DNS entries shouldn't be managed locally via `/etc/hosts` within pods. This can result in unintended and/or dangerous outcomes.
    audit: |
      Check for the existence of `hostAliases` setting in `spec`:

      ```yaml
      apiVersion: v1
      kind: Pod
      spec:
        hostAliases:
          - ip: "127.0.0.1"
            hostnames:
              - "foo.local"
              - "bar.local"
        containers:
          - name: example-app
            image: index.docker.io/yournamespace/repository
      ```
  refs:
    - title: Adding entries to Pod /etc/hosts with HostAliases
      url: https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
  query: |
    k8s.statefulset {      
      manifest['spec']['template']['spec']['hostAliases'] == null
    }
- uid: mondoo-kubernetes-best-practices-deployment-hostalias
  title: Pod should not define hostAliases
  docs:
    desc: |
      DNS entries shouldn't be managed locally via `/etc/hosts` within pods. This can result in unintended and/or dangerous outcomes.
    audit: |
      Check for the existence of `hostAliases` setting in `spec`:

      ```yaml
      apiVersion: v1
      kind: Deployment
      spec:
        ...
        spec:
          hostAliases:
          - ip: "127.0.0.1"
            hostnames:
              - "foo.local"
              - "bar.local"
          containers:
          - name: example-app
            image: index.docker.io/yournamespace/repository
      ```
  refs:
    - title: Adding entries to Pod /etc/hosts with HostAliases
      url: https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
  query: |
    k8s.deployment {
      manifest['spec']['template']['spec']['hostAliases'] == null
    }
- uid: mondoo-kubernetes-best-practices-job-hostalias
  title: Pod should not define hostAliases
  docs:
    desc: |
      DNS entries shouldn't be managed locally via `/etc/hosts` within pods. This can result in unintended and/or dangerous outcomes.
    audit: |
      Check for the existence of `hostAliases` setting in `spec`:

      ```yaml
      apiVersion: v1
      kind: Pod
      spec:
        hostAliases:
          - ip: "127.0.0.1"
            hostnames:
              - "foo.local"
              - "bar.local"
        containers:
          - name: example-app
            image: index.docker.io/yournamespace/repository
      ```
  refs:
    - title: Adding entries to Pod /etc/hosts with HostAliases
      url: https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
  query: |
    k8s.job {      
      manifest['spec']['template']['spec']['hostAliases'] == null
    }
- uid: mondoo-kubernetes-best-practices-replicaset-hostalias
  title: Pod should not define hostAliases
  docs:
    desc: |
      DNS entries shouldn't be managed locally via `/etc/hosts` within pods. This can result in unintended and/or dangerous outcomes.
    audit: |
      Check for the existence of `hostAliases` setting in `spec`:

      ```yaml
      apiVersion: v1
      kind: Pod
      spec:
        hostAliases:
          - ip: "127.0.0.1"
            hostnames:
              - "foo.local"
              - "bar.local"
        containers:
          - name: example-app
            image: index.docker.io/yournamespace/repository
      ```
  refs:
    - title: Adding entries to Pod /etc/hosts with HostAliases
      url: https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
  query: |
    k8s.replicaset {      
      manifest['spec']['template']['spec']['hostAliases'] == null
    }
- uid: mondoo-kubernetes-best-practices-daemonset-hostalias
  title: Pod should not define hostAliases
  docs:
    desc: |
      DNS entries shouldn't be managed locally via `/etc/hosts` within pods. This can result in unintended and/or dangerous outcomes.
    audit: |
      Check for the existence of `hostAliases` setting in `spec`:

      ```yaml
      apiVersion: v1
      kind: Pod
      spec:
        hostAliases:
          - ip: "127.0.0.1"
            hostnames:
              - "foo.local"
              - "bar.local"
        containers:
          - name: example-app
            image: index.docker.io/yournamespace/repository
      ```
  refs:
    - title: Adding entries to Pod /etc/hosts with HostAliases
      url: https://kubernetes.io/docs/tasks/network/customize-hosts-file-for-pods/
  query: |
    k8s.daemonset {      
      manifest['spec']['template']['spec']['hostAliases'] == null
    }
- uid: mondoo-kubernetes-best-practices-pod-default-namespace
  title: Workloads should not run in default namespace
  severity: 20
  docs:
    desc: |
      Workloads should be organized by Namespace, and the default Namespace shouldn't be used.
    audit: |
      Check to ensure no workloads are running in the default Namespace. The following command should return no Pods:

      ```yaml
      kubectl get pods -n default
      ```
    remediation: |
      For any Pods running in the default Namespace, update/redeploy the Pods (or the parent Deployment, CronJob, etc) to a non-default Namespace:

      ```yaml
      apiVersion:v1
      kind: Pod
      metadata:
        name: examplePod
        namespace: pod-namespace
      ```
  refs:
    - title: "Kubernetes best practices: Organizing with Namespaces"
      url: https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-organizing-with-namespaces
  query: |
    k8s.pod {
      namespace != "default"
    }
- uid: mondoo-kubernetes-best-practices-daemonset-default-namespace
  title: DaemonSets should not run in the default namespace
  severity: 20
  docs:
    desc: |
      Workloads should be organized by Namespace, and the default Namespace shouldn't be used.
    audit: |
      Check to ensure no workloads are running in the default Namespace. The following command should return no DaemonSets:

      ```yaml
      kubectl get daemonsets -n default
      ```
    remediation: |
      For any Daemonsets running in the default Namespace, update/redeploy the DaemonSets to a non-default Namespace:

      ```yaml
      apiVersion:apps/v1
      kind: DaemonSet
      metadata:
        name: exampleDaemonSet
        namespace: daemonset-namespace
      ```
  refs:
    - title: "Kubernetes best practices: Organizing with Namespaces"
      url: https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-organizing-with-namespaces
  query: |
    k8s.daemonset {
      namespace != "default"
    }
- uid: mondoo-kubernetes-best-practices-replicaset-default-namespace
  title: ReplicaSets should not run in the default namespace
  severity: 20
  docs:
    desc: |
      Workloads should be organized by Namespace, and the default Namespace shouldn't be used.
    audit: |
      Check to ensure no workloads are running in the default Namespace. The following command should return no ReplicaSets:

      ```yaml
      kubectl get replicasets -n default
      ```
    remediation: |
      For any ReplicaSets running in the default Namespace, update/redeploy the ReplicaSets (or the parent Deployment) to a non-default Namespace:

      ```yaml
      apiVersion:apps/v1
      kind: ReplicaSet
      metadata:
        name: exampleReplicaSet
        namespace: replicaset-namespace
      ```
  refs:
    - title: "Kubernetes best practices: Organizing with Namespaces"
      url: https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-organizing-with-namespaces
  query: |
    k8s.replicaset {
      namespace != "default"
    }
- uid: mondoo-kubernetes-best-practices-job-default-namespace
  title: Jobs should not run in the default namespace
  severity: 20
  docs:
    desc: |
      Workloads should be organized by Namespace, and the default Namespace shouldn't be used.
    audit: |
      Check to ensure no workloads are running in the default Namespace. The following command should return no Jobs:

      ```yaml
      kubectl get jobs -n default
      ```
    remediation: |
      For any Jobs running in the default Namespace, update/redeploy the Jobs (or the parent CronJobs) to a non-default Namespace:

      ```yaml
      apiVersion:batch/v1
      kind: Job
      metadata:
        name: exampleJob
        namespace: job-namespace
      ```
  refs:
    - title: "Kubernetes best practices: Organizing with Namespaces"
      url: https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-organizing-with-namespaces
  query: |
    k8s.job {
      namespace != "default"
    }
- uid: mondoo-kubernetes-best-practices-deployment-default-namespace
  title: Deployments should not run in the default namespace
  severity: 20
  docs:
    desc: |
      Workloads should be organized by Namespace, and the default Namespace shouldn't be used.
    audit: |
      Check to ensure no workloads are running in the default Namespace. The following command should return no Deployments:

      ```yaml
      kubectl get deployments -n default
      ```
    remediation: |
      For any Deployments running in the default Namespace, update/redeploy the Deployments to a non-default Namespace:

      ```yaml
      apiVersion:apps/v1
      kind: Deployment
      metadata:
        name: exampleDeployment
        namespace: deployment-namespace
      ```
  refs:
    - title: "Kubernetes best practices: Organizing with Namespaces"
      url: https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-organizing-with-namespaces
  query: |
    k8s.deployment {
      namespace != "default"
    }
- uid: mondoo-kubernetes-best-practices-statefulset-default-namespace
  title: StatefulSets should not run in the default namespace
  severity: 20
  docs:
    desc: |
      Workloads should be organized by Namespace, and the default Namespace shouldn't be used.
    audit: |
      Check to ensure no workloads are running in the default Namespace. The following command should return no StatefulSets:

      ```yaml
      kubectl get statefulsets -n default
      ```
    remediation: |
      For any StatefulSets running in the default Namespace, update/redeploy the StatefulSets to a non-default Namespace:

      ```yaml
      apiVersion:apps/v1
      kind: StatefulSet
      metadata:
        name: exampleStatefulset
        namespace: statefulset-namespace
      ```
  refs:
    - title: "Kubernetes best practices: Organizing with Namespaces"
      url: https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-organizing-with-namespaces
  query: |
    k8s.statefulset {
      namespace != "default"
    }
- uid: mondoo-kubernetes-best-practices-cronjob-default-namespace
  title: CronJobs should not run in the default namespace
  severity: 20
  docs:
    desc: |
      Workloads should be organized by Namespace, and the default Namespace shouldn't be used.
    audit: |
      Check to ensure no workloads are running in the default Namespace. The following command should return no CronJobs:

      ```yaml
      kubectl get cronjob -n default
      ```
    remediation: |
      For any CronJobs running in the default Namespace, update/redeploy the CronJobs to a non-default Namespace:

      ```yaml
      apiVersion:batch/v1
      kind: CronJob
      metadata:
        name: exampleCronJob
        namespace: cronjob-namespace
      ```
  refs:
    - title: "Kubernetes best practices: Organizing with Namespaces"
      url: https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-organizing-with-namespaces
  query: |
    k8s.cronjob {
      namespace != "default"
    }
- uid: mondoo-kubernetes-best-practices-pod-ports-hostport
  title: Pods should not bind to a host port
  severity: 40
  docs:
    desc: |
      Pods should not bind to the underlying host port. Containers that bind to the underlying host's port(s) can be limited regarding where they are scheduled as two containers cannot both bind to the same host port on the same node.
    audit: |
      Check to ensure no Pods are binding any of their containers to a host port:

      ```kubectl get pods -A -o json | jq -r '.items[] | select( (.spec.containers[].ports | . != null and any(.[].hostPort; . != null)  ) ) | .metadata.namespace + "/" + .metadata.name'  | uniq```
    remediation: |
      For any Pods that bind to a host port, update the Pods (or the Deployments/DaemonSets/CronJobs/etc that produced the Pods) to ensure they do not bind to a host port:

      ```yaml
      apiVersion: v1
      kind: Pod
      metadata:
        name: example
        namespace: example-namespace
      spec:
        containers:
          - ports:
            - containerPort: 80 # <-- ensure no 'hostPort' is defined in any entries of the port configurations
              name: http
              protocol: TCP
            - containerPort: 443
              name: https
              protocol: TCP
      ```
  query: |
    k8s.pod.podSpec {
      _['containers'] {
        _['name']
        _['ports'] == null || _['ports'].all(_['hostPort'] == null)
      }
    }
- uid: mondoo-kubernetes-best-practices-daemonset-ports-hostport
  title: DaemonSets should not bind to a host port
  severity: 40
  docs:
    desc: |
      DaemonSets should not bind to the underlying host port. Containers that bind to the underlying host's port(s) can be limited regarding where they are scheduled as two containers cannot both bind to the same host port on the same node.
    audit: |
      Check to ensure no DaemonSets are binding any of their containers to a host port:

      ```kubectl get daemonsets -A -o json | jq -r '.items[] | select( (.spec.template.spec.containers[].ports | . != null and any(.[].hostPort; . != null)  ) ) | .metadata.namespace + "/" + .metadata.name'  | uniq```
    remediation: |
      For any DaemonSets that bind to a host port, update the DaemonSets to ensure they do not bind to a host port:

      ```yaml
      apiVersion: apps/v1
      kind: DaemonSet
      metadata:
        name: example
        namespace: example-namespace
      spec:
        template:
          spec:
            containers:
              - ports:
                - containerPort: 80 # <-- ensure no 'hostPort' is defined in any entries of the port configurations
                  name: http
                  protocol: TCP
                - containerPort: 443
                  name: https
                  protocol: TCP
      ```
  query: |
    k8s.daemonset.podSpec {
      _['containers'] {
        _['name']
        _['ports'] == null || _['ports'].all(_['hostPort'] == null)
      }
    }
- uid: mondoo-kubernetes-best-practices-replicaset-ports-hostport
  title: ReplicaSets should not bind to a host port
  severity: 40
  docs:
    desc: |
      ReplicaSets should not bind to the underlying host port. Containers that bind to the underlying host's port(s) can be limited regarding where they are scheduled as two containers cannot both bind to the same host port on the same node.
    audit: |
      Check to ensure no ReplicaSets are binding any of their containers to a host port:

      ```kubectl get replicasets -A -o json | jq -r '.items[] | select( (.spec.template.spec.containers[].ports | . != null and any(.[].hostPort; . != null)  ) ) | .metadata.namespace + "/" + .metadata.name'  | uniq```
    remediation: |
      For any ReplicaSets that bind to a host port, update the ReplicaSets to ensure they do not bind to a host port:

      ```yaml
      apiVersion: apps/v1
      kind: ReplicaSet
      metadata:
        name: example
        namespace: example-namespace
      spec:
        template:
          spec:
            containers:
              - ports:
                - containerPort: 80 # <-- ensure no 'hostPort' is defined in any entries of the port configurations
                  name: http
                  protocol: TCP
                - containerPort: 443
                  name: https
                  protocol: TCP
      ```
  query: |
    k8s.replicaset.podSpec {
      _['containers'] {
        _['name']
        _['ports'] == null || _['ports'].all(_['hostPort'] == null)
      }
    }
- uid: mondoo-kubernetes-best-practices-job-ports-hostport
  title: Jobs should not bind to a host port
  severity: 40
  docs:
    desc: |
      Jobs should not bind to the underlying host port. Containers that bind to the underlying host's port(s) can be limited regarding where they are scheduled as two containers cannot both bind to the same host port on the same node.
    audit: |
      Check to ensure no Jobs are binding any of their containers to a host port:

      ```kubectl get jobs -A -o json | jq -r '.items[] | select( (.spec.template.spec.containers[].ports | . != null and any(.[].hostPort; . != null)  ) ) | .metadata.namespace + "/" + .metadata.name'  | uniq```
    remediation: |
      For any ReplicaSets that bind to a host port, update the Jobs to ensure they do not bind to a host port:

      ```yaml
      apiVersion: batch/v1
      kind: Job
      metadata:
        name: example
        namespace: example-namespace
      spec:
        template:
          spec:
            containers:
              - ports:
                - containerPort: 80 # <-- ensure no 'hostPort' is defined in any entries of the port configurations
                  name: http
                  protocol: TCP
                - containerPort: 443
                  name: https
                  protocol: TCP
      ```
  query: |
    k8s.job.podSpec {
      _['containers'] {
        _['name']
        _['ports'] == null || _['ports'].all(_['hostPort'] == null)
      }
    }
- uid: mondoo-kubernetes-best-practices-deployment-ports-hostport
  title: Deployments should not bind to a host port
  severity: 40
  docs:
    desc: |
      Deployments should not bind to the underlying host port. Containers that bind to the underlying host's port(s) can be limited regarding where they are scheduled as two containers cannot both bind to the same host port on the same node.
    audit: |
      Check to ensure no Deployments are binding any of their containers to a host port:

      ```kubectl get deployments -A -o json | jq -r '.items[] | select( (.spec.template.spec.containers[].ports | . != null and any(.[].hostPort; . != null)  ) ) | .metadata.namespace + "/" + .metadata.name'  | uniq```
    remediation: |
      For any Deployments that bind to a host port, update the Deployments to ensure they do not bind to a host port:

      ```yaml
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: example
        namespace: example-namespace
      spec:
        template:
          spec:
            containers:
              - ports:
                - containerPort: 80 # <-- ensure no 'hostPort' is defined in any entries of the port configurations
                  name: http
                  protocol: TCP
                - containerPort: 443
                  name: https
                  protocol: TCP
      ```
  query: |
    k8s.deployment.podSpec {
      _['containers'] {
        _['name']
        _['ports'] == null || _['ports'].all(_['hostPort'] == null)
      }
    }
- uid: mondoo-kubernetes-best-practices-statefulset-ports-hostport
  title: StatefulSets should not bind to a host port
  severity: 40
  docs:
    desc: |
      StatefulSets should not bind to the underlying host port. Containers that bind to the underlying host's port(s) can be limited regarding where they are scheduled as two containers cannot both bind to the same host port on the same node.
    audit: |
      Check to ensure no StatefulSets are binding any of their containers to a host port:

      ```kubectl get statefulsets -A -o json | jq -r '.items[] | select( (.spec.template.spec.containers[].ports | . != null and any(.[].hostPort; . != null)  ) ) | .metadata.namespace + "/" + .metadata.name'  | uniq```
    remediation: |
      For any StatefulSets that bind to a host port, update the StatefulSets to ensure they do not bind to a host port:

      ```yaml
      apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: example
        namespace: example-namespace
      spec:
        template:
          spec:
            containers:
              - ports:
                - containerPort: 80 # <-- ensure no 'hostPort' is defined in any entries of the port configurations
                  name: http
                  protocol: TCP
                - containerPort: 443
                  name: https
                  protocol: TCP
      ```
  query: |
    k8s.statefulset.podSpec {
      _['containers'] {
        _['name']
        _['ports'] == null || _['ports'].all(_['hostPort'] == null)
      }
    }
- uid: mondoo-kubernetes-best-practices-cronjob-ports-hostport
  title: CronJobs should not bind to a host port
  severity: 40
  docs:
    desc: |
      CronJobs should not bind to the underlying host port. Containers that bind to the underlying host's port(s) can be limited regarding where they are scheduled as two containers cannot both bind to the same host port on the same node.
    audit: |
      Check to ensure no CronJobs are binding any of their containers to a host port:

      ```kubectl get cronjobs -A -o json | jq -r '.items[] | select( (.spec.jobTemplate.spec.template.spec.containers[].ports | . != null and any(.[].hostPort; . != null)  ) ) | .metadata.namespace + "/" + .metadata.name'  | uniq```
    remediation: |
      For any CronJobs that bind to a host port, update the CronJobs to ensure they do not bind to a host port:

      ```yaml
      apiVersion: batch/v1
      kind: CronJob
      metadata:
        name: example
        namespace: example-namespace
      spec:
        jobTemplate:
          spec:
            template:
              spec:
                containers:
                  - ports:
                    - containerPort: 80 # <-- ensure no 'hostPort' is defined in any entries of the port configurations
                      name: http
                      protocol: TCP
                    - containerPort: 443
                      name: https
                      protocol: TCP
      ```
  query: |
    k8s.cronjob.podSpec {
      _['containers'] {
        _['name']
        _['ports'] == null || _['ports'].all(_['hostPort'] == null)
      }
    }
# Data Queries
- uid: mondoo-kubernetes-best-practices-gather-deployment-container
  title: Gather all Deployments
  query: |
    k8s.deployments {
      name
    }
- uid: mondoo-kubernetes-best-practices-gather-daemonset-container
  title: Gather all DaemonSets
  query: |
    k8s.daemonsets {
      name
    }
- uid: mondoo-kubernetes-best-practices-gather-statefulset-container
  title: Gather all StatefulSets
  query: |
    k8s.statefulsets {
      name
    }
- uid: mondoo-kubernetes-best-practices-gather-job-container
  title: Gather all Jobs
  query: |
    k8s.jobs {
      name
    }
- uid: mondoo-kubernetes-best-practices-gather-cronjob-container
  title: Gather all CronJobs
  query: |
    k8s.cronjobs {
      name
    }
- uid: mondoo-kubernetes-best-practices-gather-pods-security-context
  title: Gather all Pods with security context
  query: |
    k8s.pods {
      name
      namespace
      initContainers {
        name
        resources
        securityContext
      }
      containers {
        name
        resources
        livenessProbe
        securityContext
      }
    }
