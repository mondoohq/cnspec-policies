policies:
  - uid: mondoo-terraform-gcp-security
    name: Terraform HCL Security Static Analysis for Google Cloud 
    version: 1.0.0
    authors:
      - name: Mondoo, Inc
        email: hello@mondoo.com
    tags:
      mondoo.com/platform: gcp,cloud,terraform
      mondoo.com/category: security
    docs:
      desc: |
        ## Overview

        This checks for security misconfigurations in Terraform HCL for Google Cloud. 

        ## Local scan

        Local scan refer to scans of files and operating systems where `cnspec` is installed.

        ### Scan a Terraform project

        Open a terminal and run the following command:  

        ```bash
        cnspec scan terraform /path/to/terraform/directory
        ```

        ## Join the community!

        Our goal is to build policies that are simple to deploy, accurate, and actionable. 
        
        If you have any suggestions on how to improve this policy, or if you need support, [join the community](https://github.com/orgs/mondoohq/discussions) in GitHub Discussions. 
    specs:
      - title: GCP BigQuery
        asset_filter:
          query: |
            platform.name == "terraform"
            terraform.providers.one( nameLabel == "google" )
        scoring_queries:
          terraform-gcp-security-bigquery-no-public-access: null
      - title: GCP Identity and Access Management (IAM)
        asset_filter:
          query: |
            platform.name == "terraform"
            terraform.providers.one( nameLabel == "google" )
        scoring_queries:
          terraform-gcp-security-iam-no-folder-level-default-service-account-assignment: null
          terraform-gcp-security-iam-no-folder-level-service-account-impersonation: null
          terraform-gcp-security-iam-no-privileged-service-accounts: null
      - title: GCP Cloud Storage
        asset_filter:
          query: |
            platform.name == "terraform"
            terraform.providers.one( nameLabel == "google" )
        scoring_queries:
          terraform-gcp-security-storage-no-public-access: null
          terraform-gcp-security-storage-enable-ubla: null
      - title: GCP Compute
        asset_filter:
          query: |
            platform.name == "terraform"
            terraform.providers.one( nameLabel == "google" )
        scoring_queries:
          terraform-gcp-security-compute-no-public-ip: null
          terraform-gcp-security-compute-disk-encryption-customer-key: null
          terraform-gcp-security-compute-disk-encryption-required: null
          terraform-gcp-security-compute-enable-shielded-vm: null
          terraform-gcp-security-compute-enable-vpc-flow-logs: null
          terraform-gcp-security-compute-no-default-service-account: null
          terraform-gcp-security-compute-no-ip-forwarding: null
          #terraform-gcp-security-compute-no-oslogin-override: null - BUG IDENTIFIED WITH metadata attribute
          terraform-gcp-security-compute-no-plaintext-vm-disk-keys: null
          #terraform-gcp-security-compute-no-project-wide-ssh-keys: null - BUG IDENTIFIED WITH metadata attribute
          # terraform-gcp-security-compute-no-public-egress: null
          # terraform-gcp-security-compute-no-public-ingress: null
          # terraform-gcp-security-compute-no-serial-port: null
          # terraform-gcp-security-compute-project-level-oslogin: null
          # terraform-gcp-security-compute-use-secure-tls-policy: null
      - title: GCP DNS
        asset_filter:
          query: |
            platform.name == "terraform"
            terraform.providers.one( nameLabel == "google" )
        scoring_queries:
          terraform-gcp-security-dns-enable-dnssec: null
          terraform-gcp-security-dns-no-rsa-sha1: null
      - title: GCP Google Kubernetes Engine (GKE)
        asset_filter:
          query: |
            platform.name == "terraform"
            terraform.providers.one( nameLabel == "google" )
        scoring_queries:
          terraform-gcp-security-gke-enable-auto-repair: null
          terraform-gcp-security-gke-enable-auto-upgrade: null
          terraform-gcp-security-gke-enable-ip-aliasing: null
          terraform-gcp-security-gke-enable-master-networks: null
          terraform-gcp-security-gke-enable-network-policy: null
          terraform-gcp-security-gke-enable-private-cluster: null
          terraform-gcp-security-gke-enable-stackdriver-logging: null
          terraform-gcp-security-gke-enable-stackdriver-monitoring: null
          # terraform-gcp-security-gke-enforce-pod-security-policy: null - PodSecurityPolicy DEPRECATED. WE NEED TO FIGURE OUT WHAT WE WANT TO DO HERE
          terraform-gcp-security-gke-metadata-endpoints-disabled: null
          terraform-gcp-security-gke-no-client-cert-authentication: null
          terraform-gcp-security-gke-no-basic-authentication: null
          terraform-gcp-security-gke-no-public-control-plane: null
          terraform-gcp-security-gke-node-metadata-security: null
          terraform-gcp-security-gke-node-pool-uses-cos: null
          terraform-gcp-security-gke-node-shielding-enabled: null
          terraform-gcp-security-gke-use-cluster-labels: null
          terraform-gcp-security-gke-use-rbac-permissions: null
          terraform-gcp-security-gke-use-service-account: null
queries:
  - uid: terraform-gcp-security-iam-no-folder-level-default-service-account-assignment
    title: Roles should not be assigned to default service accounts
    docs:
      desc: |
        Default service accounts should not be used when granting access to folders as this can violate least privilege. It is recommended to use specialized service accounts instead.

        Some Google Cloud services create default service accounts when you first enable the API in a Google Cloud project. By default, these service accounts are granted the Editor role (roles/editor) on the Cloud project, which allows them to read and modify all resources in the Cloud project. This amount of access isn't essential for the services to work: To access resources in your Cloud project, Google Cloud services use service agents, not the default service accounts.
      audit: |
        Check if `member` is configured to use default service accounts `compute@developer.gserviceaccount.com`, `appspot.gserviceaccount.com`, or if a `data.google_compute_default_service_account` is being used

        ```hcl
        resource "google_folder_iam_member" "folder-123" {
          folder = "folder-123"
          role    = "roles/my-role"
          member  = "123-compute@developer.gserviceaccount.com"
        }

        resource "google_folder_iam_member" "folder-456" {
          folder = "folder-456"
          role    = "roles/my-role"
          member  = "123@appspot.gserviceaccount.com"
        }

        data "google_compute_default_service_account" "default" {
        }

        resource "google_folder_iam_member" "folder-789" {
          folder = "folder-789"
          role    = "roles/my-role"
          member  = data.google_compute_default_service_account.default.id
        }
        ```
      remediation: |
        Define a service account with least privilege for the role

        ```hcl
        resource "google_service_account" "limited" {
          account_id   = "account123"
          display_name = "account123"
        }
                
        resource "google_folder_iam_member" "folder-123" {
          folder = "folder-123"
          role    = "roles/my-role"
          member  = "serviceAccount:${google_service_account.limited.email}"
        }
        ```
      refs:
        - title: Using IAM securely
          url: https://cloud.google.com/iam/docs/using-iam-securely
        - title: Google Cloud Docs - Types of service accounts
          url: https://cloud.google.com/iam/docs/service-accounts#types
        - title: Terraform Documentation - google_folder_iam_member Resource
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/google_folder_iam#google_folder_iam_member
    query: |
      terraform.resources.where( nameLabel  == "google_folder_iam_member") { 
        arguments['member'] != /.+@appspot\.gserviceaccount\.com/ && 
        arguments['member'] != /.+-compute@developer\.gserviceaccount\.com/ &&
        arguments['member'] != /data\.google_compute_default_account/
      }
  - uid: terraform-gcp-security-iam-no-folder-level-service-account-impersonation
    title: Users should not be granted service account access at the folder level
    docs:
      desc: |
        Users with service account access at the folder level can impersonate any service account. Instead, they should be given access to particular service accounts as required.
      audit: |
        Check if `role` is configured with `roles/iam.serviceAccountUser`

        ```hcl
        resource "google_folder_iam_binding" "folder-123" {
          folder = "folder-123"
          role    = "roles/iam.serviceAccountUser"
        }
        ```
      remediation: |
        Define a custom role with least privilege

        ```hcl
          resource "google_folder_iam_binding" "folder-123" {
            folder = "folder-123"
            role    = "roles/custom-role"
          }
        ```
      refs:
        - title: Managing service account impersonation
          url: https://cloud.google.com/iam/docs/impersonating-service-accounts
        - title: Terraform Documentation - google_folder_iam_binding Resource
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/google_folder_iam#google_folder_iam_binding
    query: |
      terraform.resources.where( nameLabel  == "google_folder_iam_binding") { 
        arguments['role'] != /iam\.serviceAccountUser/
      }
  - uid: terraform-gcp-security-iam-no-privileged-service-accounts
    title: Service accounts should not have roles assigned with excessive privileges
    docs:
      desc: |
        Service accounts should have a minimal set of permissions assigned to accomplish their job. They should never have excessive access because if compromised, an attacker can escalate privileges and take over the entire account.
      audit: |
        Check if `role` is configured with basic roles: `roles/editor`, `roles/owner`

        ```hcl
        resource "google_service_account" "test" {
          account_id   = "account123"
          display_name = "account123"
        }

        resource "google_project_iam_member" "project" {
          project = "your-project-id"
          role    = "roles/owner"
          member  = "serviceAccount:${google_service_account.test.email}"
        }
        ```
      remediation: |
        Define a custom role with least privilege

        ```hcl
        resource "google_service_account" "test" {
          account_id   = "account123"
          display_name = "account123"
        }

        resource "google_project_iam_member" "project" {
          project = "your-project-id"
          role    = "roles/logging.logWriter"
          member  = "serviceAccount:${google_service_account.test.email}"
        }
        ```
      refs:
        - title: Google Cloud Docs - Understanding roles
          url: https://cloud.google.com/iam/docs/understanding-roles
        - title: Terraform Documentation - google_project_iam_member Resource
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/google_project_iam
    query: |
      terraform.resources.where( nameLabel  == "google_project_iam_member") { 
        arguments['role'] != /roles\/owner/ &&
        arguments['role'] != /roles\/editor/
      }
  - uid: terraform-gcp-security-storage-no-public-access
    title: Ensure that Cloud Storage bucket is not publicly accessible
    docs:
      desc: |
        Google Cloud Storage buckets that define 'allUsers' or 'allAuthenticatedUsers' as members in an IAM member/binding causes data to be exposed outside of the organization. This can lead to exposure of sensitive data. The recommended approach is to restrict public access.
      audit: |
        Check if `members` is configured with `allAuthenticatedUsers` or `allUsers`

        ```hcl
        resource "google_storage_bucket_iam_binding" "allAuthenticatedUsers" {
          bucket = google_storage_bucket.default.name
          role = "roles/storage.admin"
          members = [
            "allAuthenticatedUsers",
          ]
        }

        resource "google_storage_bucket_iam_binding" "allUsers" {
          bucket = google_storage_bucket.default.name
          role = "roles/storage.admin"
          members = [
            "allUsers",
          ]
        }
        ```
      remediation: |
        Restrict public access to the bucket.

        ```hcl
        resource "google_storage_bucket_iam_binding" "binding" {
          bucket = google_storage_bucket.default.name
          role = "roles/storage.admin"
          members = [
            "user:jane@example.com",
          ]
        }
        ```
      refs:
        - title: Google Cloud Docs - Overview of access control
          url: https://cloud.google.com/storage/docs/access-control
        - title: Terraform Documentation - google_storage_bucket_iam_binding Resource
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/storage_bucket_iam#google_storage_bucket_iam_binding
    query: |
      terraform.resources.where( nameLabel  == "google_storage_bucket_iam_binding") { 
        attributes['members']['value'] { _ != /allUsers/ && _ != /allAuthenticatedUsers/} 
      }
  - uid: terraform-gcp-security-storage-enable-ubla
    title: Ensure that Cloud Storage buckets have uniform bucket-level access enabled
    docs:
      desc: |
        Google Cloud Storage buckets should be configured with uniform bucket-level access.
        
        When you enable uniform bucket-level access on a bucket, Access Control Lists (ACLs) are disabled, and only bucket-level Identity and Access Management (IAM) permissions grant access to that bucket and the objects it contains. You revoke all access granted by object ACLs and the ability to administrate permissions using bucket ACLs.
      audit: |
        Check if `uniform_bucket_level_access` is set to `true`

        ```hcl
        resource "google_storage_bucket" "static-site" {
          name          = "image-store.com"
          location      = "EU"
          force_destroy = true
          
          uniform_bucket_level_access = false
          
          website {
            main_page_suffix = "index.html"
            not_found_page   = "404.html"
          }
          cors {
            origin          = ["http://image-store.com"]
            method          = ["GET", "HEAD", "PUT", "POST", "DELETE"]
            response_header = ["*"]
            max_age_seconds = 3600
          }
        }
        ```
      remediation: |
        Configure `uniform_bucket_level_access` to `true`

        ```hcl
        resource "google_storage_bucket" "static-site" {
          name          = "image-store.com"
          location      = "EU"
          force_destroy = true
          
          uniform_bucket_level_access = true
          
          website {
            main_page_suffix = "index.html"
            not_found_page   = "404.html"
          }
          cors {
            origin          = ["http://image-store.com"]
            method          = ["GET", "HEAD", "PUT", "POST", "DELETE"]
            response_header = ["*"]
            max_age_seconds = 3600
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Uniform Bucket Level Access
          url: https://cloud.google.com/storage/docs/uniform-bucket-level-access
        - title: Terraform Documentation - google_storage_bucket Resource
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/storage_bucket#uniform_bucket_level_access
    query: |
      terraform.resources.where( nameLabel  == "google_storage_bucket") { 
         arguments['uniform_bucket_level_access'] == true
      }
  - uid: terraform-gcp-security-compute-no-public-ip
    title: Compute instances should not be publicly exposed to the internet
    docs:
      desc: |
        Google Cloud compute instances that have a public IP address are exposed on the internet and are at risk to attack. 
        
      audit: |
        Check if the `access_config` is empty.

        ```hcl
        resource "google_compute_instance" "bad_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }

          network_interface {
            network = "default"

            access_config {
              // Ephemeral IP
            }
          }
        }
        ```
      remediation: |
        Configure compute instance without empty `access_config`

        ```hcl
        resource "google_compute_instance" "good_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }

          network_interface {
            network = "default"
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Ephemeral Public IP
          url: https://cloud.google.com/compute/docs/ip-addresses#ephemeraladdress
        - title: Terraform Documentation - google_compute_instance Resource
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance#access_config
    query: |
      terraform.resources.where( nameLabel  == "google_compute_instance") { 
        blocks.where( type == "network_interface") { 
          blocks.where( type == "access_config") {
            arguments.values.length != 0 
          } 
        } 
      }
  - uid: terraform-gcp-security-compute-disk-encryption-customer-key
    title: Disks should be encrypted with Customer Supplied Encryption Keys
    docs:
      desc: |
        Google Cloud compute instances should use disk encryption using a customer-supplied encryption key. If you do not provide an encryption key when creating the disk, then the disk will be encrypted using an automatically generated key, and you do not need to provide the key to use the disk later.
        
      audit: |
        Check if `disk_encryption_key` key is defined and that the arguments are not empty strings.

        ```hcl
        resource "google_compute_disk" "bad_example" {
          name  = "test-disk"
          type  = "pd-ssd"
          zone  = "us-central1-a"
          image = "debian-9-stretch-v20200805"
          labels = {
            environment = "dev"
          }
          physical_block_size_bytes = 4096
        }
        ```
      remediation: |
        Configure compute instance with `disk_encryption_key` and `kms_key_self_link` defined.

        ```hcl
        resource "google_compute_disk" "good_example" {
          name  = "test-disk"
          type  = "pd-ssd"
          zone  = "us-central1-a"
          image = "debian-9-stretch-v20200805"
          labels = {
            environment = "dev"
          }
          physical_block_size_bytes = 4096
          disk_encryption_key {
            kms_key_self_link = "something"
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Protect resources by using Cloud KMS keys
          url: https://cloud.google.com/compute/docs/disks/customer-managed-encryption#encrypt_a_new_persistent_disk_with_your_own_keys
        - title: Terraform Documentation - disk_encryption_key attribute
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_disk#disk_encryption_key
    query: |
      terraform.resources.where( nameLabel  == "google_compute_disk" ) { 
        blocks.one( type == "disk_encryption_key") 
      }
      terraform.resources.where( nameLabel  == "google_compute_disk" && blocks.one( type == "disk_encryption_key") ) { 
        blocks.where( type == "disk_encryption_key") { 
          arguments != "" 
        }
      }
  - uid: terraform-gcp-security-compute-disk-encryption-required
    title: Disk encryption Keys should not be passed as plaintext
    docs:
      desc: |
        Google Cloud compute instances should use disk encryption using a customer-supplied encryption key. One of the options is for the `disk_encryption_key` is `raw_key`, which is the key in plaintext. 
        
        Sensitive values such as raw encryption keys should not be included in your Terraform code and should be stored securely by a secrets manager.
        
      audit: |
        Check if the `access_config` is empty

        ```hcl
        resource "google_compute_disk" "good_example" {
          disk_encryption_key {
            raw_key="b2ggbm8gdGhpcyBpcyBiYWQ="
          }
        }
        ```
      remediation: |
        Configure compute instance with `disk_encryption_key` and `kms_key_self_link` defined

        ```hcl
        resource "google_compute_disk" "good_example" {
          disk_encryption_key {
            kms_key_self_link = google_kms_crypto_key.my_crypto_key.id
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Encrypt disks with customer-supplied encryption keys
          url: https://cloud.google.com/compute/docs/disks/customer-supplied-encryptioncustomer-managed-encryption#encrypt_a_new_persistent_disk_with_your_own_keys
        - title: Terraform Documentation - disk_encryption_key attribute
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_disk#disk_encryption_key
    query: |
      terraform.resources.where( nameLabel  == "google_compute_disk" && blocks.one( type == "disk_encryption_key") ) {
        blocks.where( type == "disk_encryption_key") { 
          arguments.keys[0] != "raw_key" 
        } 
      }
  - uid: terraform-gcp-security-compute-enable-shielded-vm
    title: Verify shielded VM is enabled on compute instances
    docs:
      desc: |
        Shielded VMs are virtual machines (VMs) on Google Cloud hardened by a set of security controls that help defend against rootkits and bootkits. Using Shielded VMs helps protect enterprise workloads from threats like remote attacks, privilege escalation, and malicious insiders. Shielded VMs leverage advanced platform security capabilities such as secure and measured boot, a virtual trusted platform module (vTPM), UEFI firmware, and integrity monitoring.

        **Secure Boot** helps ensure that the system only runs authentic software by verifying the digital signature of all boot components, and halting the boot process if signature verification fails.

        **Integrity monitoring** helps you understand and make decisions about the state of your VM instances. Integrity monitoring compares the most recent boot measurements to the integrity policy baseline and returns a pair of pass/fail results depending on whether they match or not, one for the early boot sequence and one for the late boot sequence.
        
      audit: |
        Check if the `shielded_instance_config` is configured on the instance, and if `enable_vtpm` and `enable_integrity_monitoring` are set to `false`

        ```hcl
        resource "google_compute_instance" "bad_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }

          shielded_instance_config {
            enable_vtpm = false
            enable_integrity_monitoring = false
          }
        }
        ```
      remediation: |
        Configure `shielded_instance_config` without `enable_vtpm` and `enable_integrity_monitoring`, or configure `enable_vtpm` and `enable_integrity_monitoring` explicitly to `true`

        ```hcl
        resource "google_compute_instance" "good_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }

          shielded_instance_config {
            enable_vtpm = true
            enable_integrity_monitoring = true
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Encrypt disks with customer-supplied encryption keys
          url: https://cloud.google.com/compute/docs/disks/customer-supplied-encryptioncustomer-managed-encryption#encrypt_a_new_persistent_disk_with_your_own_keys
        - title: Terraform Documentation - enable_vtpm attribute
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance#enable_vtpm
    query: |
      terraform.resources.where( nameLabel  == "google_compute_instance" ) { 
        blocks.one( type == "shielded_instance_config" ) 
      }
      terraform.resources.where( nameLabel  == "google_compute_instance" && blocks.one( type == "shielded_instance_config" )) {
        blocks.where( type == "shielded_instance_config") { 
          attributes['enable_vtpm'] == null || attributes['enable_vtpm']['value'] == true
        } 
      }
      terraform.resources.where( nameLabel  == "google_compute_instance" && blocks.one( type == "shielded_instance_config" )) {
        blocks.where( type == "shielded_instance_config") { 
          attributes['enable_integrity_monitoring'] == null || attributes['enable_integrity_monitoring']['value'] == true
        } 
      }
  - uid: terraform-gcp-security-compute-enable-vpc-flow-logs
    title: Verify VPC flow logs enabled on compute instances
    docs:
      desc: |
        VPC flow logs record information about all traffic, which is a vital tool in reviewing anomalous traffic. Google Compute Engine subnetworks that do not have VPC flow logs enabled have limited information for auditing and awareness.

        Note: Google Compute Engine subnets configured as INTERNAL_HTTPS_LOAD_BALANCER do not support VPC flow logs. Compute subnetworks with `purpose INTERNAL_HTTPS_LOAD_BALANCER` attribute will not be evaluated.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_compute_subnetwork" "bad_example" {
          name          = "test-subnetwork"
          ip_cidr_range = "10.2.0.0/16"
          region        = "us-central1"
          network       = google_compute_network.custom-test.id
          secondary_ip_range {
            range_name    = "tf-test-secondary-range-update1"
            ip_cidr_range = "192.168.10.0/24"
          }
        }

        resource "google_compute_network" "custom-test" {
          name                    = "test-network"
          auto_create_subnetworks = false
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_compute_subnetwork" "good_example" {
          name          = "test-subnetwork"
          ip_cidr_range = "10.2.0.0/16"
          region        = "us-central1"
          network       = google_compute_network.custom-test.id
          secondary_ip_range {
            range_name    = "tf-test-secondary-range-update1"
            ip_cidr_range = "192.168.10.0/24"
          }
          log_config {
            aggregation_interval = "INTERVAL_10_MIN"
            flow_sampling        = 0.5
            metadata             = "INCLUDE_ALL_METADATA"
          }
        }

        resource "google_compute_network" "custom-test" {
          name                    = "test-network"
          auto_create_subnetworks = false
        }

        ```
      refs:
        - title: Google Cloud Docs - Using VPC Flow Logs
          url: https://cloud.google.com/vpc/docs/using-flow-logs
        - title: Terraform Documentation - enable_flow_logs Attribute
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_subnetwork#enable_flow_logs
    query: |
      terraform.resources.where( nameLabel  == "google_compute_subnetwork" && arguments['purpose'] != "INTERNAL_HTTPS_LOAD_BALANCER" ) { 
        blocks.one( type == "log_config")  
      }
  - uid: terraform-gcp-security-compute-no-default-service-account
    title: Compute instances should not use the default service account
    docs:
      desc: |
        The default service account has full project access. Provisioning instances using the default service account gives the instance full access to the project. Compute instances should instead be assigned the minimal access they need.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_compute_instance" "default" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }

          service_account {
            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            email  = "1234567890-compute@developer.gserviceaccount.com"
            scopes = ["cloud-platform"]
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service_account_id"
          display_name = "Service Account"
        }

        resource "google_compute_instance" "default" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }

          network_interface {
            network = "default"

            access_config {
              // Ephemeral IP
            }
          }

          metadata = {
            foo = "bar"
          }

          metadata_startup_script = "echo hi > /test.txt"

          service_account {
            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            email  = google_service_account.default.email
            scopes = ["cloud-platform"]
          }
        }

        ```
      refs:
        - title: Google Cloud Docs - Service accounts
          url: https://cloud.google.com/compute/docs/access/service-accounts
        - title: Terraform Documentation - compute_instance#nested_service_account
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance#nested_service_account
    query: |
      terraform.resources.where( nameLabel  == "google_compute_instance" && blocks.one( type == "service_account") ) {
        blocks.where( type == "service_account" ) {
          attributes['email'] != null
        } 
      }
      terraform.resources.where( nameLabel  == "google_compute_instance" && blocks.one( type == "service_account") ) { 
        blocks.where( type == "service_account" ) { 
          attributes['email'] != /.+-compute@developer\.gserviceaccount.com/
        }
      }
  - uid: terraform-gcp-security-compute-no-ip-forwarding
    title: Compute instances should be configured with IP forwarding
    docs:
      desc: |
        Disabling IP forwarding ensures the instance can only receive packets addressed to the instance and can only send packets with a source address of the instance.

        The attribute `can_ip_forward` is optional on `google_compute_instance` and defaults to `false`. Instances with `can_ip_forward = true` will fail. 
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_compute_instance" "bad_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }
          
          can_ip_forward = false
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_compute_instance" "bad_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
          }

          // Local SSD disk
          scratch_disk {
            interface = "SCSI"
          }
          
          can_ip_forward = false
        }

        ```
      refs:
        - title: Google Cloud Docs - Service accounts
          url: https://cloud.google.com/compute/docs/access/service-accounts
        - title: Terraform Documentation - compute_instance#nested_service_account
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance#nested_service_account
    query: |
      terraform.resources.where( nameLabel  == "google_compute_instance" && attributes['can_ip_forward']) {
        attributes['can_ip_forward']['value'] == false 
      }
  # - uid: terraform-gcp-security-compute-no-oslogin-override
  #   title: Instances should not override the project setting for OS Login
  #   docs:
  #     desc: |
  #       OS Login automatically revokes the relevant SSH keys when an IAM user has their access revoked. Access via SSH key cannot be revoked automatically when an IAM user is removed. Enable OS Login at project level and remove instance-level overrides.
        
  #     audit: |
  #       The following example will fail because `metadata` block includes `enable-oslogin = false`:

  #       ```terraform

  #       resource "google_compute_instance" "default" {
  #         name         = "test"
  #         machine_type = "e2-medium"
  #         zone         = "us-central1-a"

  #         boot_disk {
  #           initialize_params {
  #             image = "debian-cloud/debian-9"
  #           }
  #         }

  #         // Local SSD disk
  #         scratch_disk {
  #           interface = "SCSI"
  #         }

  #         metadata = {
  #           enable-oslogin = false
  #         }
  #       }

  #       ```
  #     remediation: |
  #       The following example will pass because `metadata` block does not include `enable-oslogin = false`:

  #       ```terraform

  #       resource "google_compute_instance" "default" {
  #         name         = "test"
  #         machine_type = "e2-medium"
  #         zone         = "us-central1-a"

  #         boot_disk {
  #           initialize_params {
  #             image = "debian-cloud/debian-9"
  #           }
  #         }

  #         // Local SSD disk
  #         scratch_disk {
  #           interface = "SCSI"
  #         }

  #         metadata = {
  #         }
  #       }

  #       ```
  #     refs:
  #       - title: Google Cloud Docs - Default VM metadata values
  #         url: https://cloud.google.com/compute/docs/metadata/default-metadata-values#instance-attributes-metadata
  #       - title: Terraform Documentation - compute_instance#metadata
  #         url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance#metadata
  #   query: |
  #     terraform.resources.where( nameLabel  == "google_compute_instance" && arguments.keys.one( "metadata" ) ) { 
  #       arguments.keys.contains("metadata")
  #     }

  - uid: terraform-gcp-security-compute-no-plaintext-vm-disk-keys
    title: VM disk encryption keys should not be provided in plaintext
    docs:
      desc: |
        Providing your encryption key in plaintext format means anyone with access to the source code also has access to the key.

        When encrypting a `boot_disk`, it is not recommended to use the `disk_encryption_key_raw` argument as this passes the key in plaintext, which is not secure. Consider using `kms_key_self_link` or a secrets manager instead. 
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_compute_instance" "bad_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
            disk_encryption_key_raw = "something"
          }

        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

         resource "google_compute_instance" "bad_example" {
          name         = "test"
          machine_type = "e2-medium"
          zone         = "us-central1-a"

          tags = ["foo", "bar"]

          boot_disk {
            initialize_params {
              image = "debian-cloud/debian-9"
            }
            kms_key_self_link = "kmsKeyName"
          }

        }
        ```
      refs:
        - title: Google Cloud Docs - Service accounts
          url: https://cloud.google.com/compute/docs/access/service-accounts
        - title: Terraform Documentation - compute_instance#nested_service_account
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance#nested_service_account
    query: |
      terraform.resources.where( nameLabel  == "google_compute_instance" ) { 
        blocks { arguments.keys { _ != 'disk_encryption_key_raw' } } 
      }

  # - uid: terraform-gcp-security-compute-no-project-wide-ssh-keys
  #   title: Disable project-wide SSH keys for all instances
  #   docs:
  #     desc: |
  #       Google compute instances allow for the configuring of SSH keys via instance metadata, including configuring project-wide SSH keys. Configuring project-wide SSH keys is NOT recommended as a compromise of those keys can lead to a access to all instances in the project. 
        
  #     audit: |
  #       The following example will fail:

  #       ```terraform

  #       resource "google_compute_instance" "default" {
  #         name         = "test"
  #         machine_type = "e2-medium"
  #         zone         = "us-central1-a"

  #         tags = ["foo", "bar"]

  #         boot_disk {
  #           initialize_params {
  #             image = "debian-cloud/debian-9"
  #           }
  #         }

  #         metadata = {
  #           block-project-ssh-keys = false
  #         }

  #       }

  #       ```
  #     remediation: |
  #       The following example will pass:

  #       ```terraform

  #       resource "google_compute_instance" "default" {
  #         name         = "test"
  #         machine_type = "e2-medium"
  #         zone         = "us-central1-a"

  #         tags = ["foo", "bar"]

  #         boot_disk {
  #           initialize_params {
  #             image = "debian-cloud/debian-9"
  #           }
  #         }

  #         metadata = {}

  #       }
  #       ```
  #     refs:
  #       - title: Google Cloud Docs - Providing public SSH keys to instances
  #         url: https://cloud.google.com/compute/docs/instances/connecting-advanced#provide-key
  #       - title: Terraform Documentation - google_compute_instance
  #         url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_instance
  #   query: |
  #     terraform.resources.where( nameLabel  == "google_compute_instance" ) {  
  #     }
  - uid: terraform-gcp-security-bigquery-no-public-access
    title: BigQuery datasets should only be accessible within the organization
    docs:
      desc: |
        BigQuery datasets should not be configured to provide access to `allAuthenticatedUsers` as this provides any authenticated GCP user, even those outside of your organization, access to your BigQuery dataset. This can lead to exposure of sensitive data to the public internet.

        Configure access permissions with higher granularity and least privilege principles.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_bigquery_dataset" "bad_example" {
          dataset_id                  = "example_dataset"
          friendly_name               = "test"
          description                 = "This is a test description"
          location                    = "EU"
          default_table_expiration_ms = 3600000

          labels = {
            env = "default"
          }

          access {
            role          = "OWNER"
            special_group = "allAuthenticatedUsers"
          }

          access {
            role   = "READER"
            domain = "hashicorp.com"
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_bigquery_dataset" "good_example" {
          dataset_id                  = "example_dataset"
          friendly_name               = "test"
          description                 = "This is a test description"
          location                    = "EU"
          default_table_expiration_ms = 3600000

          labels = {
            env = "default"
          }

          access {
            role          = "OWNER"
            user_by_email = google_service_account.bqowner.email
          }

          access {
            role   = "READER"
            domain = "hashicorp.com"
          }
        }

        resource "google_service_account" "bqowner" {
          account_id = "bqowner"
        }
        ```
      refs:
        - title: Google Cloud Docs - Controlling access to datasets
          url: https://cloud.google.com/bigquery/docs/dataset-access-controls
        - title: Terraform Documentation - bigquery_dataset 
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/bigquery_dataset#special_group
    query: |
      terraform.resources.where( nameLabel  == "google_bigquery_dataset" ) { 
        blocks { arguments.values.none("allAuthenticatedUsers") }
      }

  - uid: terraform-gcp-security-dns-enable-dnssec
    title: Cloud DNS should use DNSSEC
    docs:
      desc: |
        DNSSEC authenticates DNS responses, preventing MITM attacks and impersonation. Unverified DNS responses could lead to man-in-the-middle attacks. 

        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_dns_managed_zone" "bad_example" {
          name        = "example-zone"
          dns_name    = "example-${random_id.rnd.hex}.com."
          description = "Example DNS zone"
          labels = {
            foo = "bar"
          }
          dnssec_config {
            state = "off"
          }
        }

        resource "random_id" "rnd" {
          byte_length = 4
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_dns_managed_zone" "good_example" {
          name        = "example-zone"
          dns_name    = "example-${random_id.rnd.hex}.com."
          description = "Example DNS zone"
          labels = {
            foo = "bar"
          }
          dnssec_config {
            state = "on"
          }
        }

        resource "random_id" "rnd" {
          byte_length = 4
        }
        ```
      refs:
        - title: Google Cloud Docs - Manage DNSSEC configuration 
          url: https://cloud.google.com/dns/docs/dnssec-config?hl=en
        - title: Terraform Documentation - dns_managed_zone#state
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/dns_managed_zone#state
    query: |
      terraform.resources.where( nameLabel  == "google_dns_managed_zone" ) { 
        blocks.where( type == "dnssec_config" ) { 
          attributes['state']['value'] != "off"  
        } 
      }      

  - uid: terraform-gcp-security-dns-no-rsa-sha1
    title: Zone signing should not use RSA SHA1
    docs:
      desc: |
        RSA SHA1 is a weaker algorithm than SHA2-based algorithms such as RSA SHA256/512. 

        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_dns_managed_zone" "foo" {
          name     = "foobar"
          dns_name = "foo.bar."
          
          dnssec_config {
            state         = "on"
            non_existence = "nsec3"
          }
        }
          
        data "google_dns_keys" "foo_dns_keys" {
          managed_zone = google_dns_managed_zone.foo.id
          zone_signing_keys {
            algorithm = "rsasha1"
          }
        }
          
        output "foo_dns_ds_record" {
          description = "DS record of the foo subdomain."
          value       = data.google_dns_keys.foo_dns_keys.key_signing_keys[0].ds_record
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_dns_managed_zone" "foo" {
          name     = "foobar"
          dns_name = "foo.bar."
          
          dnssec_config {
            state         = "on"
            non_existence = "nsec3"
          }
        }
          
        data "google_dns_keys" "foo_dns_keys" {
          managed_zone = google_dns_managed_zone.foo.id
          zone_signing_keys {
            algorithm = "rsasha512"
          }
        }
          
        output "foo_dns_ds_record" {
          description = "DS record of the foo subdomain."
          value       = data.google_dns_keys.foo_dns_keys.key_signing_keys[0].ds_record
        }
        ```
      refs:
        - title: Google Cloud Docs - View DNSSEC keys 
          url: https://cloud.google.com/dns/docs/dnskeys?hl=en
        - title: Terraform Documentation - dns_managed_zone#algorithm
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/dns_managed_zone#algorithm
    query: |
      terraform.datasources.where( nameLabel  == "google_dns_keys" ) { 
        blocks { attributes['algorithm']['value'] != "rsasha1" }
      }
  - uid: terraform-gcp-security-gke-enable-auto-repair
    title: Kubernetes should have 'Automatic repair' enabled
    docs:
      desc: |
        Automatic repair will monitor nodes and attempt repair when a node fails multiple subsequent health checks. Failing nodes will require manual repair.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_container_node_pool" "bad_example" {
          name       = "my-node-pool"
          cluster    = google_container_cluster.primary.id
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
          management {
            auto_repair = false
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "primary" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
        }

        resource "google_container_node_pool" "good_example" {
          name       = "my-node-pool"
          cluster    = google_container_cluster.primary.id
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
          management {
            auto_repair = true
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Auto-repairing nodes
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-repair
        - title: Terraform Documentation - container_node_pool#auto_repair
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_node_pool#auto_repair
    query: |
      terraform.resources.where( nameLabel == "google_container_node_pool" ) { 
        blocks.where( type == "management") { 
          arguments['auto_repair'] != false 
        }
      }

  - uid: terraform-gcp-security-gke-enable-auto-upgrade
    title: Kubernetes should have 'Automatic upgrade' enabled
    docs:
      desc: |
        Automatic updates keep nodes updated with the latest cluster master version.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "primary" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
        }

        resource "google_container_node_pool" "bad_example" {
          name       = "my-node-pool"
          cluster    = google_container_cluster.primary.id
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
          management {
            auto_upgrade = false
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "primary" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
        }

        resource "google_container_node_pool" "good_example" {
          name       = "my-node-pool"
          cluster    = google_container_cluster.primary.id
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
          management {
            auto_upgrade = true
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Auto-upgrading nodes
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/node-auto-upgrades
        - title: Terraform Documentation - container_node_pool#auto_upgrade
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_node_pool#auto_upgrade
    query: |
      terraform.resources.where( nameLabel == "google_container_node_pool" ) { 
        blocks.where( type == "management") { 
          arguments['auto_upgrade'] != false 
        }
      }

  - uid: terraform-gcp-security-gke-enable-ip-aliasing
    title: Clusters should have IP aliasing enabled
    docs:
      desc: |
        IP aliasing allows the reuse of public IPs internally, removing the need for a NAT gateway.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          ip_allocation_policy = {}
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }
        `,`
        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          ip_allocation_policy     {
            cluster_secondary_range_name  = "some range name"
            services_secondary_range_name = "some range name"
          }
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Enable privately used public IP address ranges
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/alias-ips#enable_pupis
        - title: Terraform Documentation - container_cluster#ip_allocation_policy
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#ip_allocation_policy
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        blocks.one( type == "ip_allocation_policy" ) 
      }
  - uid: terraform-gcp-security-gke-enable-master-networks
    title: Master authorized networks should be configured on GKE clusters
    docs:
      desc: |
        Enabling authorized networks means you can restrict master access to a fixed set of CIDR ranges.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "primary" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "primary" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          master_authorized_networks_config = [{
            cidr_blocks = [{
              cidr_block = "10.10.128.0/24"
              display_name = "internal"
            }]
          }]
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Add authorized networks for control plane access
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/authorized-networks
        - title: Terraform Documentation - container_cluster#nested_master_authorized_networks_config
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#nested_master_authorized_networks_config
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        arguments.keys.contains("master_authorized_networks_config")  
      }
  - uid: terraform-gcp-security-gke-enable-network-policy
    title: Network Policy should be enabled on GKE clusters
    docs:
      desc: |
        Enabling a network policy allows the segregation of network traffic by namespace.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          network_policy {
            enabled = false
          }
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          network_policy {
            enabled = true
          }
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Creating a network policy
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/network-policy
        - title: Terraform Documentation - container_cluster#enabled
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#enabled
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        blocks.one( type == "network_policy" )  
      }
  - uid: terraform-gcp-security-gke-enable-private-cluster
    title: Clusters should be set to private
    docs:
      desc: |
        Enabling private nodes on a cluster ensures the nodes are only available internally as they will only be assigned internal addresses.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          network_policy {
            enabled = false
          }
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          network_policy {
            enabled = true
          }
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Creating a network policy
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/network-policy
        - title: Terraform Documentation - container_cluster#enabled
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#enabled
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        blocks.one( type == "network_policy" )  
      }

  - uid: terraform-gcp-security-gke-enable-stackdriver-logging
    title: Stackdriver Logging should be enabled
    docs:
      desc: |
        StackDriver logging provides a useful interface to all of stdout/stderr for each container and should be enabled for monitoring, debugging, etc. Without Stackdriver, visibility to the cluster will be reduced.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          logging_service = "logging.googleapis.com"
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          logging_service = "logging.googleapis.com/kubernetes"
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Overview of Google Cloud's operations suite for GKE
          url: https://cloud.google.com/stackdriver/docs/solutions/gke
        - title: Terraform Documentation - container_cluster#enabled
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#enabled
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        attributes.keys.contains( "logging_service" ) 
      }
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        attributes['logging_service']['value'] == 'logging.googleapis.com/kubernetes'
      }

  - uid: terraform-gcp-security-gke-enable-stackdriver-monitoring
    title: Stackdriver Monitoring should be enabled
    docs:
      desc: |
        StackDriver monitoring aggregates logs, events, and metrics from your Kubernetes environment on GKE to help you understand your application's behavior in production.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          monitoring_service = "monitoring.googleapis.com"
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_service_account" "default" {
          account_id   = "service-account-id"
          display_name = "Service Account"
        }

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          monitoring_service = "monitoring.googleapis.com/kubernetes"
        }

        resource "google_container_node_pool" "primary_preemptible_nodes" {
          name       = "my-node-pool"
          location   = "us-central1"
          cluster    = google_container_cluster.primary.name
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes    = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Overview of Google Cloud's operations suite for GKE
          url: https://cloud.google.com/stackdriver/docs/solutions/gke
        - title: Terraform Documentation - container_cluster#monitoring_service
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#monitoring_service
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        attributes.keys.contains( "monitoring_service" ) 
      }
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        attributes['monitoring_service']['value'] == 'monitoring.googleapis.com/kubernetes'
      }

  # - uid: terraform-gcp-security-gke-enforce-pod-security-policy
  #   title: Pod security policy enforcement not defined
  #   docs:
  #     desc: |
  #       By default, Pods in Kubernetes can operate with capabilities beyond what they require. You should constrain the Pod's capabilities to only those required for that workload. Kubernetes offers controls for restricting your Pods to execute with only explicitly granted capabilities. Pod Security Policy allows you to set smart defaults for your Pods, and enforce controls you want to enable across your fleet. The policies you define should be specific to the needs of your application
        
  #     audit: |
  #       The following example will fail:

  #       ```terraform

  #       resource "google_container_cluster" "bad_example" {
  #         pod_security_policy_config {
  #           enabled = "false"
  #         }
  #       }

  #       ```
  #     remediation: |
  #       The following example will pass:

  #       ```terraform

  #       resource "google_container_cluster" "bad_example" {
  #         pod_security_policy_config {
  #           enabled = "true"
  #         }
  #       }
  #       ```
  #     refs:
  #       - title: Google Cloud Docs - Overview of Google Cloud's operations suite for GKE
  #         url: https://cloud.google.com/kubernetes-engine/docs/how-to/hardening-your-cluster#admission_controllers
  #       - title: Terraform Documentation - container_cluster#monitoring_service
  #         url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#monitoring_service
  #   query: |
  #     terraform.resources.where( nameLabel == "google_container_cluster" ) { 
  #       attributes.keys.contains( "monitoring_service" ) 
  #     }
  #     terraform.resources.where( nameLabel == "google_container_cluster" ) { 
  #       attributes['monitoring_service']['value'] == 'monitoring.googleapis.com/kubernetes'
  #     }

  - uid: terraform-gcp-security-gke-metadata-endpoints-disabled
    title: Legacy metadata endpoints enabled
    docs:
      desc: |
        The Compute Engine instance metadata server exposes legacy v0.1 and v1beta1 endpoints, which do not enforce metadata query headers. This is a feature in the v1 APIs that makes it more difficult for a potential attacker to retrieve instance metadata. Unless specifically required, we recommend you disable these legacy APIs. When setting the `metadata` block, the default value for `disable-legacy-endpoints` is set to `true`, they should not be explicitly enabled.
        
      audit: |
        The following example will fail:

        ```terraform

        resource "google_container_cluster" "bad_example" {
          metadata {
            disable-legacy-endpoints = false
          }
        }

        ```
      remediation: |
        The following example will pass:

        ```terraform

        resource "google_container_cluster" "good_example" {
          metadata {
            disable-legacy-endpoints = true
          }
        }
        ```
      refs:
        - title: Google Cloud Docs - Protect Node Metadata
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/hardening-your-cluster#protect_node_metadata
        - title: Terraform Documentation - container_cluster#monitoring_service
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#metadata
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        attributes['metadata']['value']['disable-legacy-endpoints'] != false
      }

  - uid: terraform-gcp-security-gke-no-client-cert-authentication
    title: Clusters should not use client certificates for authentication
    docs:
      desc: |
        There are several methods of authenticating to the Kubernetes API server. In GKE, the supported methods are service account bearer tokens, OAuth tokens, and x509 client certificates. Prior to GKE's integration with OAuth, a one-time generated x509 certificate or static password were the only available authentication methods, but are now not recommended and should be disabled. These methods present a wider surface of attack for cluster compromise and have been disabled by default since GKE version 1.12. If you are using legacy authentication methods, we recommend that you turn them off. Authentication with a static password is deprecated and has been removed since GKE version 1.19.

        Existing clusters should move to OAuth.
        
      audit: |
        The following example will fail due to the `master_auth` block that includes the `issue_client_certificate = true` configuration which is set to `false` by default:

        ```terraform

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          master_auth {
            client_certificate_config {
              issue_client_certificate = true
            }
          }
        }
        ```
      remediation: |
        The following example will pass since the `master_auth` block is not specified and secure defaults are used instead:

        ```terraform

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
        }
        ```
        The following example will pass because the `master_auth` block is explicitly configuring `issue_client_certificate = false`:

        ```terraform

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1

          master_auth {
            client_certificate_config {
              issue_client_certificate = false
            }
        }
        ```
      refs:
        - title: Google Cloud Docs - Leave legacy client authentication methods disabled
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/hardening-your-cluster#restrict_authn_methods
        - title: Terraform Documentation - container_cluster#monitoring_service
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#master_auth
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        blocks.where( type == "master_auth" ) { 
          blocks { attributes['issue_client_certificate']['value'] != true }
        }
      }

  - uid: terraform-gcp-security-gke-no-basic-authentication
    title: Clusters should not use basic authentication
    docs:
      desc: |
        There are several methods of authenticating to the Kubernetes API server. In GKE, the supported methods are service account bearer tokens, OAuth tokens, and x509 client certificates. Prior to GKE's integration with OAuth, a one-time generated x509 certificate or static password were the only available authentication methods, but are now not recommended and should be disabled. These methods present a wider surface of attack for cluster compromise and have been disabled by default since GKE version 1.12. If you are using legacy authentication methods, we recommend that you turn them off. Authentication with a static password is deprecated and has been removed since GKE version 1.19.

        Existing clusters should move to OAuth.
        
      audit: |
        The following example will fail due to the `master_auth` block that includes the `username` and `password` configuration which is set to a value other than `""`:

        ```terraform

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          master_auth {
            username = "kubeadmin"
            password = var.cluster_password
          }
        }
        ```
      remediation: |
        The following example will pass since the `master_auth` block is not specified and secure defaults are used instead:

        ```terraform

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
        }
        ```

        The following example will pass because the `master_auth` block is explicitly configuring basic auth to be disabled:

        ```terraform

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          remove_default_node_pool = true
          initial_node_count       = 1

          master_auth {
            username = ""
            password = "" 
            client_certificate_config {
              issue_client_certificate = false
            }
        }
        ```
      refs:
        - title: Google Cloud Docs - Leave legacy client authentication methods disabled
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/hardening-your-cluster#restrict_authn_methods
        - title: Terraform Documentation - container_cluster#monitoring_service
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#master_auth
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        blocks.where( type == "master_auth" ) { attributes['username']['value'] == null ||  attributes['username']['value'] == "" }
      }
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        blocks.where( type == "master_auth" ) { attributes['password']['value'] == null ||  attributes['password']['value'] == "" }
      }

  - uid: terraform-gcp-security-gke-no-public-control-plane
    title: GKE Control Plane should not be publicly accessible
    docs:
      desc: |
        Authorized networks allow you to specify CIDR ranges and allow IP addresses in those ranges to access your cluster control plane endpoint using HTTPS. Exposing the Kubernetes control plane to the public internet by specifying a CIDR block of "0.0.0.0/0" is not recommended. Public clusters can have up to 50 authorized network CIDR ranges; private clusters can have up to 100.

      audit: |
        The following example will fail due to the `master_authorized_networks_config` block that specifies `cidr_block = "0.0.0.0/0"` which is publicly accessible:

        ```terraform

        resource "google_container_cluster" "primary" {
          name     = "my-gke-cluster"
          location = "us-central1"

          remove_default_node_pool = true
          initial_node_count       = 1
          master_authorized_networks_config = [{
            cidr_blocks = [{
              cidr_block = "0.0.0.0/0"
              display_name = "external"
            }]
          }]
        }
        ```
      remediation: |
        The following example will pass since the `master_authorized_networks_config` block configures an internal `cidr_block`:

        ```terraform

        resource "google_container_cluster" "primary" {
          name     = "my-gke-cluster"
          location = "us-central1"

          remove_default_node_pool = true
          initial_node_count       = 1
          master_authorized_networks_config = [{
            cidr_blocks = [{
              cidr_block = "10.10.128.0/24"
              display_name = "internal"
            }]
          }]
        }

        ```
      refs:
        - title: Google Cloud Docs - Add authorized networks for control plane access
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/authorized-networks
        - title: Terraform Documentation - container_cluster#master_authorized_networks_config
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#master_authorized_networks_config
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        arguments['master_authorized_networks_config'][0]['cidr_blocks'] { _['cidr_block'] != "0.0.0.0/0" } 
      }

  - uid: terraform-gcp-security-gke-node-metadata-security
    title: Node metadata value disables metadata concealment
    docs:
      desc: |
        GKE metadata concealment protects some potentially sensitive system metadata from user workloads running on your cluster. Metadata concealment is scheduled to be deprecated in the future and Google recommends using Workload Identity instead instead of metadata concealment. This check is looking for configuration that exposes metadata completely. 
        
      audit: |
        The following example will fail due to the `node_config` block that specifies `node_metadata = "EXPOSE"`:

        ```terraform

        resource "google_container_node_pool" "bad_example" {
          node_config {
            workload_metadata_config {
              node_metadata = "EXPOSE"
            }
          }
        }
        ```

        The following example will fail due to the `node_config` block that specifies `node_metadata = "UNSPECIFIED"`:

        ```terraform

        resource "google_container_node_pool" "bad_example" {
          node_config {
            workload_metadata_config {
              node_metadata = "UNSPECIFIED"
            }
          }
        }
        ```

      remediation: |
        The following example will pass due to the `node_config` block that specifies `node_metadata = "GKE_METADATA_SERVER"` (recommended): 

        ```terraform

        resource "google_container_node_pool" "bad_example" {
          node_config {
            workload_metadata_config {
              node_metadata = "GKE_METADATA_SERVER"
            }
          }
        }

        ```

        The following example will pass due to the `node_config` block that specifies `node_metadata = "SECURE"`: 

        ```terraform

        resource "google_container_node_pool" "bad_example" {
          node_config {
            workload_metadata_config {
              node_metadata = "SECURE"
            }
          }
        }

        ```
      refs:
        - title: Google Cloud Docs - Using Workload Identity
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity
        - title: Google Cloud Docs - Metadata concealment
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/protecting-cluster-metadata#concealment
        - title: Terraform Documentation - container_cluster#node_metadata
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#node_metadata
    query: |
      terraform.resources.where( nameLabel == "google_container_node_pool" ) { 
        blocks.where( type == "node_config") { 
          blocks { attributes['node_metadata']['value'] != "EXPOSE"  }
        }
      }
      terraform.resources.where( nameLabel == "google_container_node_pool" ) { 
        blocks.where( type == "node_config") { 
          blocks { attributes['node_metadata']['value'] != "UNSPECIFIED"  }
        }
      }

  - uid: terraform-gcp-security-gke-node-pool-uses-cos
    title: Ensure Container-Optimized OS (cos) is used for Kubernetes Engine Clusters Node image
    docs:
      desc: |
        GKE supports several OS image types but COS_CONTAINERD is the recommended OS image to use on cluster nodes for enhanced security. COS_CONTAINERD is the recommended OS image to use on cluster nodes. 
        
      audit: |
        The following example will fail due to the `node_config` block that specifies `image_type = "something"`:

        ```terraform

        resource "google_container_node_pool" "bad_example" {
          name       = "my-node-pool"
          cluster    = google_container_cluster.primary.id
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
            image_type = "something"
          }
        }
        ```

      remediation: |
        The following example will pass due to the `node_config` block that specifies `image_type = "COS_CONTAINERD"` (recommended): 

        ```terraform

        resource "google_container_node_pool" "good_example" {
          name       = "my-node-pool"
          cluster    = google_container_cluster.primary.id
          node_count = 1

          node_config {
            preemptible  = true
            machine_type = "e2-medium"

            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes = [
              "https://www.googleapis.com/auth/cloud-platform"
            ]
            image_type = "COS_CONTAINERD"
          }
        }

        ```
      refs:
        - title: Google Cloud Docs - Node images
          url: https://cloud.google.com/kubernetes-engine/docs/concepts/node-images
        - title: Terraform Documentation - container_cluster#image_type
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#image_type
    query: |
      terraform.resources.where( nameLabel == "google_container_node_pool" ) { 
        blocks.where( type == "node_config") { 
          attributes['image_type']['value'] == 'COS_CONTAINERD' 
        } 
      }

  - uid: terraform-gcp-security-gke-node-shielding-enabled
    title: Shielded GKE nodes not enabled
    docs:
      desc: |
        Node identity and integrity can't be verified without shielded GKE nodes. CIS GKE Benchmark Recommendation: 6.5.5. Shielded GKE Nodes provide strong, verifiable node identity and integrity to increase the security of GKE nodes and should be enabled on all GKE clusters.

        `enable_shielded_nodes` is an optional argument and is set to `true` by default, and should not be set to `false`.
        
      audit: |
        The following example will fail due to the `enable_shielded_nodes` is set to `false`: 

        ```terraform

        resource "google_container_cluster" "bad_example" {
          enable_shielded_nodes = "false"
        }
        ```

      remediation: |
        The following example will pass due to the `enable_shielded_nodes` is set to `true`: 

        ```terraform

        resource "google_container_cluster" "good_example" {
          enable_shielded_nodes = "true"
        }

        ```
      refs:
        - title: Google Cloud Docs - Enable Shielded GKE nodes
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/hardening-your-cluster#shielded_nodes
        - title: Terraform Documentation - container_cluster#enable_shielded_nodes
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#enable_shielded_nodes
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        arguments['enable_shielded_nodes'] != false 
      }

  - uid: terraform-gcp-security-gke-use-cluster-labels
    title: Clusters should be configured with Labels
    docs:
      desc: |
        Cluster labels are key-value pairs that helps you organize your Google Cloud clusters. You can attach a label to each resource, then filter the resources based on their labels. Information about labels is forwarded to the billing system, so you can break down your billed charges by label.

        The `resource_labels` argument is optional when using the `google_container_cluster` resource. 
        
      audit: |
        The following example will fail because the `resource_labels` argument is not defined for the cluster: 

        ```terraform

        resource "google_container_cluster" "bad_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          remove_default_node_pool = true
          initial_node_count       = 1
        }

        ```

      remediation: |
        The following example will pass because the `resource_labels` argument is defined for the cluster: 

        ```terraform

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          # We can't create a cluster with no node pool defined, but we want to only use
          # separately managed node pools. So we create the smallest possible default
          # node pool and immediately delete it.
          remove_default_node_pool = true
          initial_node_count       = 1
          resource_labels = {
            "env" = "staging"
          }
        }

        ```
      refs:
        - title: Google Cloud Docs - Creating and managing cluster labels
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/creating-managing-labels
        - title: Terraform Documentation - container_cluster#resource_labels
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#resource_labels
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        arguments.keys.contains( "resource_labels" ) 
      }

  - uid: terraform-gcp-security-gke-use-rbac-permissions
    title: Legacy ABAC permissions are enabled
    docs:
      desc: |
        By default, ABAC is disabled for clusters created using GKE version 1.8 and later. In Kubernetes, RBAC is used to grant permissions to resources at the cluster and namespace level. RBAC allows you to define roles with rules containing a set of permissions. RBAC has significant security advantages over ABAC.

        The `enable_legacy_abac` is set to `false` by default. 
        
      audit: |
        The following example will fail because the `enable_legacy_abac` argument is set to `true`: 

        ```terraform

        resource "google_container_cluster" "bad_example" {
          enable_legacy_abac = true
        }

        ```

      remediation: |
        The following example will pass because the `enable_legacy_abac` argument is explicitly set to `false` (omitting the argument will also pass):

        ```terraform

        resource "google_container_cluster" "good_example" {
          name     = "my-gke-cluster"
          location = "us-central1"

          enable_legacy_abac = false
        }

        ```
      refs:
        - title: Google Cloud Docs - Leave ABAC disabled 
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/hardening-your-cluster#leave_abac_disabled
        - title: Terraform Documentation - container_cluster#enable_legacy_abac
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#enable_legacy_abac
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        arguments['enable_legacy_abac'] != true
      }

  - uid: terraform-gcp-security-gke-use-service-account
    title: Checks for service account defined for GKE nodes
    docs:
      desc: |
        Each GKE node has an Identity and Access Management (IAM) Service Account associated with it. By default, nodes are given the Compute Engine default service account, which you can find by navigating to the IAM section of the Cloud Console. This account has broad access by default, making it useful to wide variety of applications, but it has more permissions than are required to run your Kubernetes Engine cluster. You should create and use a minimally privileged service account for your nodes to use instead of the Compute Engine default service account.
        
      audit: |
        The following example will fail because the `node_config` block does not contain a `service_account` argument: 

        ```terraform

        resource "google_container_cluster" "bad_example" {
          name               = "marcellus-wallace"
          location           = "us-central1-a"
          initial_node_count = 3

          node_config {
            labels = {
              foo = "bar"
            }
            tags = ["foo", "bar"]
          }
          timeouts {
            create = "30m"
            update = "40m"
          }
        }

        ```

      remediation: |
        The following example will pass because the `node_config` block contains a `service_account` argument: 

        ```terraform

        resource "google_container_cluster" "bad_example" {
          name               = "marcellus-wallace"
          location           = "us-central1-a"
          initial_node_count = 3

          node_config {
            # Google recommends custom service accounts that have cloud-platform scope and permissions granted via IAM Roles.
            service_account = google_service_account.default.email
            oauth_scopes = [
              "https://www.googleapis.com/auth/cloud-platform"
            
            labels = {
              foo = "bar"
            }
            tags = ["foo", "bar"]
          }
          timeouts {
            create = "30m"
            update = "40m"
          }
        }

        ```
      refs:
        - title: Google Cloud Docs - Use least privilege Google service accounts
          url: https://cloud.google.com/kubernetes-engine/docs/how-to/hardening-your-cluster#use_least_privilege_sa
        - title: Terraform Documentation - container_cluster#service_account
          url: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#service_account
    query: |
      terraform.resources.where( nameLabel == "google_container_cluster" ) { 
        blocks.where( type == "node_config" ) { 
          arguments.keys.contains("service_account") 
        }
      }
      terraform.resources.where( nameLabel == "google_container_node_pool" ) { 
        blocks.where( type == "node_config" ) { 
          arguments.keys.contains("service_account") 
        }
      }