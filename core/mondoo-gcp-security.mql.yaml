# Copyright (c) Mondoo, Inc.
# SPDX-License-Identifier: BUSL-1.1

policies:
  - uid: mondoo-gcp-security
    name: Mondoo Google Cloud (GCP) Security
    version: 1.1.0
    license: BUSL-1.1
    tags:
      mondoo.com/category: security
      mondoo.com/platform: gcp,cloud
    authors:
      - name: Mondoo, Inc
        email: hello@mondoo.com
    docs:
      desc: |
        The Mondoo Google Cloud (GCP) Security policy is designed to identify critical misconfigurations that could leave your Google Cloud infrastructure vulnerable to attackers. This policy helps organizations detect and remediate security risks before they can be exploited, reducing the likelihood of unauthorized access, data breaches, privilege escalation, and operational disruptions.

        ## Join the community!

        Our goal is to build policies that are simple to deploy, accurate, and actionable. This policy is open-source and we welcome contributions from the community, whether it's adding new checks, refining existing ones, or providing feedback. If you have suggestions to improve this policy, visit our [cnspec-policies repository](https://github.com/mondoohq/cnspec-policies).
    groups:
      - title: GCP Project
        filters: |
          asset.family.contains('google')
          asset.runtime == 'gcp'
        checks:
          - uid: mondoo-gcp-security-block-project-wide-ssh-keys-enabled-vm-instances
          - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible
          - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled
          - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account
          - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api
          - uid: mondoo-gcp-security-oslogin-enabled-project
    scoring_system: highest impact
queries:
  - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account
    title: Ensure that instances are not configured to use the default service account
    impact: 95
    variants:
      - uid: gcp-compute-instances-configured-use-default-service-account-single
      - uid: gcp-compute-instances-configured-use-default-service-account-terraform-hcl
      - uid: gcp-compute-instances-configured-use-default-service-account-terraform-plan
      - uid: gcp-compute-instances-configured-use-default-service-account-terraform-state
    docs:
      desc: |
        New projects that have enabled the Compute Engine API have a Compute Engine default service account, which contains the following email pattern:

        ```bash
        -compute@developer.gserviceaccount.com
        ```

        The Compute Engine default service account is created with the IAM basic Editor role, but you can modify your service account's roles to control the service account's access to Google APIs.

        You can disable or delete this service account from your project, but doing so might cause any applications that depend on the service account's credentials to fail. If you accidentally delete the Compute Engine default service account, you can try to recover the account within 30 days. For more information, see Creating and managing service accounts.

        It is recommended that you do not configure instances with the default service account. Instead, create a user account using the principle of least privilege.
      audit: |
        __cnquery run__

        To audit your Google Cloud Project with `cnquery run`:

        1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

        2. Run this query:

          ```mql
          cnquery run gcp project <project-id> -c "gcp.compute.instances.where( name != /^gke/ ) {id name serviceAccounts.where( email == /^.*compute@developer\.gserviceaccount\.com$/ )}"
          ```

        __cnquery shell__

        To audit your Google Cloud Project with `cnquery shell`:

        1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

        2. Launch `cnquery shell`:

          ```bash
          cnquery run gcp project <project-id>
          ```

        3. Run this query:

          ```mql
          gcp.compute.instances.where( name != /^gke/ ) {id name serviceAccounts.where(email == /^.*compute@developer\.gserviceaccount\.com$/ )}
          ```
      remediation: |
        ### Terraform

        To provision or update a compute instance with a custom service account:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          service_account {
            email  = "example@example.com"
            scopes = ['user-email", "compute-ro", "storage-ro']
          }
        }
        ```

        ### Google Cloud Console

        To change the policy using the GCP Console, follow these steps:

        1. Log in to the GCP Console at https://console.cloud.google.com.
        2. Select the Organization and Project where the instance you want to update is running.
        3. Navigate to **Compute Engine**.
        4. Select the compute instance that you want to update.
        5. If the instance is not stopped, select **Stop**. Wait for the instance to stop.
        6. Select **Edit**.
        7. Scroll down to the Service Account section.
        8. Select a different service account.
        9. Select **Save**.
        10. Select **START**.

        ### gcloud cli

        To update the service account using the `gcloud` cli:

        1. Stop the instance:

          ```bash
          gcloud compute instances stop INSTANCE_NAME
          ```

        2. Update the instance:

          ```bash
          gcloud compute instances set-service-account INSTANCE_NAME --serviceaccount=SERVICE_ACCOUNT --scopes [SCOPE1, SCOPE2...]
          ```

        3. Restart the instance:

          ```bash
          gcloud compute instances start INSTANCE_NAME
          ```
  - uid: gcp-compute-instances-configured-use-default-service-account-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
        gcp.compute.instance.serviceAccounts.none(
          email == /^.*compute@developer\.gserviceaccount\.com$/
        )
  - uid: gcp-compute-instances-configured-use-default-service-account-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_compute_instance').any(
        blocks.where(type == 'service_account').one(type == 'service_account')
      )
  - uid: gcp-compute-instances-configured-use-default-service-account-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance').none(
        change.after.contains(/^.*compute@developer\.gserviceaccount\.com$/)
      )
  - uid: gcp-compute-instances-configured-use-default-service-account-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance'){ 
        values.service_account.contains(/^.*compute@developer\.gserviceaccount\.com$/) 
      }

  - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api
    title: Ensure instances are not configured to use the default service account with full access to all Cloud APIs
    impact: 90
    variants:
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-single
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-hcl
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-plan
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-state
    docs:
      desc: |
        Google compute instances provisioned with full access to all cloud APIs pose a security risk to a GCP environment. Instances should instead be provisioned using a non-default service account, and limited permissions to cloud APIs using the principle of least privilege.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Run this query:

          ```mql
          cnquery run gcp project <project-id> -c "gcp.compute.instances.where( name != /^gke/ ) {id name serviceAccounts.where( email == /^.*compute@developer\.gserviceaccount\.com$/ ) {email scopes}}"
          ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Launch `cnquery shell`:

          ```bash
          cnquery shell gcp
          ```

         3. Run this query:

          ```mql
          gcp.compute.instances.where(name != /^gke/) {id name serviceAccounts.where(email == /^.*compute@developer\.gserviceaccount\.com$/) {email scopes}}
          ```
      remediation: |
        ### Terraform

        To provision or update a compute instance with Terraform:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          service_account {
            # Google recommends custom service accounts with cloud-platform scope and permissions granted via IAM Roles.
            email  = google_service_account.default.email
            scopes = ['cloud-platform']
          }
        }
        ```

        ### Google Cloud Console

        To change the policy using the Google Cloud Console:

        1. Log in to the GCP Console at https://console.cloud.google.com.
        2. Select the Organization and Project where the instance you want to update is running.
        3. Navigate to **Compute Engine**.
        4. Select the compute instance that you want to update.
        5. If the instance is not stopped, select **Stop**. Wait for the instance to stop.
        6. Select **Edit**.
        7. Scroll down to the Service Account section.
        8. Select a different service account or ensure Allow full access to all Cloud APIs is not selected.
        9. Select **Save**.
        10. Select **START**.

        ### gcloud cli

        To update the service account using the `gcloud` cli:

        1. Stop the instance:

          ```bash
          gcloud compute instances stop INSTANCE_NAME
          ```

        2. Update the instance:

          ```bash
          gcloud compute instances set-service-account INSTANCE_NAME --serviceaccount=SERVICE_ACCOUNT --scopes [SCOPE1, SCOPE2...]
          ```

        3. Restart the instance:

          ```bash
          gcloud compute instances start INSTANCE_NAME
          ```
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      gcp.compute.instance.serviceAccounts.none(
        scopes == 'https://www.googleapis.com/auth/cloud-platform'
      )
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.resources.where(nameLabel == 'google_compute_instance') { 
        blocks.where(type == 'service_account') { 
          arguments.scopes.none(_ == 'https://www.googleapis.com/auth/cloud-platform') 
        } 
      }
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance') { 
        change.after.service_account.map(scopes).first.none(_ == 'https://www.googleapis.com/auth/cloud-platform') 
      }
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance') { 
        values.service_account.map(scopes).first.where(_ == 'https://www.googleapis.com/auth/cloud-platform') 
      }

  - uid: mondoo-gcp-security-block-project-wide-ssh-keys-enabled-vm-instances
    title: Ensure "Block Project-wide SSH keys" is enabled for VM instances
    impact: 70
    variants:
      - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-single
      - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-hcl
      - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-plan
      - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-state
    docs:
      desc: |
        Project-wide SSH keys can be used to login into all instances within a project. While using project-wide SSH keys eases SSH key management, if SSH keys are compromised, the potential security risk can impact all instances within a project.

        The recommended approach is to use instance-specific SSH keys instead of common/shared project-wide SSH keys.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Run this query:

          ```mql
          cnquery run gcp -c "gcp.compute.instances {id name metadata['block-project-ssh-keys'] }"
          ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Launch `cnquery shell`:

          ```bash
          cnquery shell gcp
          ```

         3. Run this query:

          ```mql
          gcp.compute.instances {id name metadata['block-project-ssh-keys'] }
          ```
      remediation: |
        ### Terraform

        To provision or update a compute instance with Terraform:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          metadata = {
            block-project-ssh-keys = true
          }
        }
        ```

        ### Google Cloud Console

        To change the policy using the GCP Console:

        1. Log in to the GCP Console at https://console.cloud.google.com.
        2. Select the organization/project where the instance(s) you want to update are running.
        3. Navigate to **Compute Engine**.
        4. Select the instance you want to update.
        5. Select **EDIT** in the toolbar.
        6. Under the **Security and access** section, select the **Block project-wide SSH keys** option.
        7. Select **SAVE**.

        Repeat these steps for each impacted Instance.

        ### gcloud cli

        To update an instance using the `gcloud` cli:

        1. Update the instance:

          ```bash
          gcloud compute instances add-metadata INSTANCE_NAME --metadata block-projectssh-keys=TRUE
          ```
  - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-single
    filters: asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance.metadata['block-project-ssh-keys'] == true
  - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-hcl
    filters: asset.platform == 'terraform-hcl''
    mql: |
      terraform.resources.where(nameLabel == 'google_compute_instance') { 
        blocks { 
          blocks.where(attributes['metadata'] != null) { 
            _.attributes['metadata'].value.contains('block-project-ssh-keys') 
          } 
        } 
      }
  - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-plan
    filters: asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance') { 
        change.after['metadata'].first['block-project-ssh-keys'] == true 
      }
  - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance') { 
        values.metadata['block-project-ssh-keys'] == true 
      }

  - uid: mondoo-gcp-security-oslogin-enabled-project
    title: Ensure oslogin is enabled for compute instances
    impact: 70
    variants:
      - uid: gcp-compute-oslogin-enabled-project-single
      - uid: gcp-compute-oslogin-enabled-project-terraform-state
    docs:
      desc: |
        OS Login lets you use Compute Engine Identity and Access Management (IAM) roles to grant or revoke SSH access to your Linux instances. OS Login is an alternative to managing instance access by adding and removing SSH keys in metadata.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Run this query:

          ```mql
          cnquery run gcp project <project-id> -c "gcp.compute.instances {id name metadata['enable-oslogin'] == true}"
          ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Launch `cnquery shell`:

          ```bash
          cnquery shell gcp project <project-id>
          ```

         3. Run this query:

          ```mql
          gcp.compute.instances {id name metadata['enable-oslogin'] }
          ```
      remediation: |
        ### Terraform

        To configure OS Login for a project:

        ```hcl
        resource "google_compute_project_metadata" "default" {
          metadata = {
            enable-oslogin = "TRUE"
          }
        }
        ```

        To provision or update a compute instance with Terraform:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          metadata = {
            enable-oslogin = true
          }
        }
        ```

        ### Google Cloud Console

        To configure OS Login for a project via Google Cloud Console:

        1. In the Google Cloud console, go to the **Metadata** page.
        2. Select **EDIT**.
        3. Add a metadata entry, setting the key to `enable-oslogin` and the value to `TRUE`.
        4. Select **SAVE** to apply the changes.

        To configure OS Login for an existing instance:

        1. In the Google Cloud console, go to the **Compute Engine**.
        2. Select the name of the instance that you want to enable OS Login on.
        3. On the instance details page, select **EDIT**.
        4. Under **Custom metadata**, add a metadata entry, setting the key to `enable-oslogin` and the value to `TRUE`.
        5. Select **SAVE**.

        ### gcloud cli

        To update OS Login for a project using the `gcloud` cli:

          ```bash
          gcloud compute project-info add-metadata --metadata enable-oslogin=TRUE
          ```

        To update OS Login for an existing instance using the `gcloud` cli:

          ```bash
          gcloud compute instances add-metadata INSTANCE_NAME --metadata enable-oslogin=TRUE
          ```
  - uid: gcp-compute-oslogin-enabled-project-single
    filters: asset.platform 'gcp-compute-instance'
    mql:
      gcp.compute.instance.metadata['enable-oslogin'] == true
  - uid: gcp-compute-oslogin-enabled-project-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance') { 
        values.metadata['enable-oslogin'] == true
      }

  - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible
    title: Ensure that Cloud Storage buckets are not anonymously or publicly accessible
    impact: 90
    variants:
      - uid: gcp-storage-cloud-storage-bucket-anonymously-publicly-accessible-single
    docs:
      desc: |
        Public access prevention protects Cloud Storage buckets and objects from being accidentally exposed to the public. When you enforce public access prevention, no one can make data in applicable buckets public through IAM policies or ACLs.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Run this query:

           ```mql
           cnquery run gcp -c "gcloud.storage.buckets { iamPolicy { members {*} } } "
           ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Launch `cnquery shell`:

           ```bash
           cnquery shell gcp
           ```

         3. Run this query:

           ```mql
           gcloud.storage.buckets { iamPolicy { members {*} } }
           ```
      remediation: |
        ### Terraform

        To update public access configuration using Terraform, ensure `allUsers` and `allAuthenticatedUsers` are not set:

        ```hcl
        resource "google_storage_bucket_iam_binding" "binding" {
          bucket = google_storage_bucket.default.name
          role = "roles/storage.admin"
          members = [
            "user:jane@example.com",
          ]
        }
        ```

        ```hcl
        resource "google_storage_bucket_iam_member" "member" {
          bucket = google_storage_bucket.default.name
          role = "roles/storage.admin"
          member = "user:jane@example.com"
        }
        ```

        ### Google Cloud Console
        1. In the Google Cloud console, go to the **Cloud Storage Bucket** page.
        2. For the bucket you want to enforce public access prevention on, select the more actions menu.
        3. Select **Edit access** from the drop-down menu.
        4. In the Public access card, select **Prevent public access** to enforce public access prevention.
        5. Select **Confirm**.

        ### gcloud cli

        Update an existing storage bucket with the `gcloud` cli:

        ```bash
        gcloud storage buckets update gs://BUCKET_NAME --no-pap
        ```
  - uid: gcp-storage-cloud-storage-bucket-anonymously-publicly-accessible-single
    filters: asset.platform == 'gcp-storage-bucket'
    mql: |
      gcp.storage.bucket.iamPolicy.all(members.none(_ == 'allUsers'))
      gcp.storage.bucket.iamPolicy.all(members.none(_ == 'allAuthenticatedUsers'))

  - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled
    title: Ensure that Cloud Storage buckets have uniform bucket-level access enabled
    impact: 60
    variants:
      - uid: gcp-storage-cloud-storage-buckets-uniform-bucket-level-access-enabled-single
    docs:
      desc: |
        Cloud Storage offers two systems for granting users permission to access your buckets and objects: IAM and Access Control Lists (ACLs). These systems act in parallel - in order for a user to access a Cloud Storage resource, only one of the systems needs to grant the user permission. IAM is used throughout Google Cloud and allows you to grant a variety of permissions at the bucket and project levels. ACLs are used only by Cloud Storage and have limited permission options, but they allow you to grant permissions on a per-object basis.

        It is recommended to enable uniform bucket-level access on Cloud Storage buckets. Uniform bucket-level access is used to unify and simplify how you grant access to your Cloud Storage resources. Cloud Storage offers two systems that act in parallel to grant users permission to access buckets and objects:
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Run this query:

           ```bash
           cnquery run gcp -c "gcloud.storage.buckets { iamConfiguration['UniformBucketLevelAccess']['Enabled'] }"
           ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Launch `cnquery shell`:

           ```bash
           cnquery shell gcp
           ```

         3. Run this query:

           ```mql
           gcloud.storage.buckets { iamConfiguration['UniformBucketLevelAccess']['Enabled'] }
           ```
      remediation: |
        ### Terraform

        ```hcl
        resource "google_storage_bucket" "example" {
          name     = "test-bucket"
          bucket_policy_only = true
          uniform_bucket_level_access = true
        }
        ```

        ### Google Cloud Console

        1. In the Google Cloud console, go to the **Cloud Storage Buckets** page.
        2. In the list of buckets, select the name of the desired bucket.
        3. Select the **Permissions** tab near the top of the page.
        4. In the text box named **Access Control**, select the **Switch to** link. Note that the text box disappears 90 days after you enable uniform bucket-level access.
        5. In the pop-up menu that appears, select **Fine-grained**.
        6. Select **Save**.

        ### gcloud cli

        ```bash
        gsutil uniformbucketlevelaccess set STATE gs://BUCKET_NAME
        ```
  - uid: gcp-storage-cloud-storage-buckets-uniform-bucket-level-access-enabled-single
    filters: asset.platform 'gcp-storage-bucket'
    mql: gcp.storage.bucket.iamConfiguration.UniformBucketLevelAccess.enabled == true

  - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed
    title: Ensure Cloud SQL MySQL instances are not publicly exposed
    impact: 100
    variants:
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-all
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-hcl
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-plan
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-state
    docs:
      desc: |
        Assigning public IP addresses to Cloud SQL MySQL instances expands the potential attack surface, making databases accessible from the public internet and increasing security risks.

        The recommended practice is to configure instances exclusively with private IP addresses. This enhances security by isolating the database within your VPC network and can reduce latency for internal applications. Be aware that removing a public IP will disrupt existing connections that depend on it; establish and test private connectivity paths before making the change.
      audit: |
        **Using the Google Cloud Console**

          1. Navigate to the Cloud SQL Instances page within the Google Cloud Console: https://console.cloud.google.com/sql/instances
          2. Review each MySQL instance listed. For every primary (non-replica) Second Generation instance, examine its networking details to confirm that a Private IP address is assigned and that no Public IP address is present.

        ** Using the Google Cloud CLI **

          1. Obtain a list of all your Cloud SQL instances:

            ```bash
            gcloud sql instances list
            ```

          2. For each instance identified as `backendType: SECOND_GEN` and `instanceType: CLOUD_SQL_INSTANCE` (primary instance), retrieve its full configuration details. Read replicas (`instanceType: READ_REPLICA_INSTANCE`) inherit network settings, and First Generation instances do not support private IPs, so they can be skipped for this check.

            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```

          3. Inspect the `ipAddresses` section in the output for the instance. Verify that an entry exists with `type: PRIVATE`. Crucially, ensure there is no entry with `type: PRIMARY`, as this indicates a public IP address. While an instance can technically possess both during transitions, the secure state is having only the `PRIVATE` type assigned.
      remediation: |
        **Using the Google Cloud Console**

        1.  Access the Cloud SQL Instances overview page in the Google Cloud Console: https://console.cloud.google.com/sql/instances
        2.  Click on the name of the target instance to view its configuration details.
        3.  Navigate to the **Connections** settings tab.
        4.  Under the **Networking** section, locate and uncheck the box labeled **Public IP**.
        5.  Confirm the modification by clicking the **Save** button.

        **Using the Google Cloud CLI**

        1.  Modify the target instance to remove its public IP address and ensure it's associated with a VPC network for private IP access. Replace `INSTANCE_NAME` with the actual instance name and `VPC_NETWORK_NAME` with the desired VPC network name:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --network=VPC_NETWORK_NAME --no-assign-ip
            ```
            *Note: If the instance is already associated with the correct VPC network for private IP, you might only need the `--no-assign-ip` flag.*
        2.  Verify that the public IP address has been removed by inspecting the instance's configuration:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```
            Check the `ipAddresses` section in the output to confirm the absence of an entry with `type: PRIMARY`.

        **Prevention:**

        To proactively enforce that new Cloud SQL instances are not created with public IP addresses, implement the `Restrict Public IP access on Cloud SQL instances` Organization Policy. You can configure this policy at: https://console.cloud.google.com/iam-admin/orgpolicies/sql-restrictPublicIp
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(maintenanceVersion.contains('MYSQL')) {
        ipAddresses.all(
          _.type != "PRIMARY"
        )
      }
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance') { 
        blocks { 
          blocks.where(attributes['ipv4_enabled'] != null) { 
            _.attributes['ipv4_enabled'].value == true 
          } 
        } 
      }
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance') { 
        change.after['settings'].first['ip_configuration'].first['ipv4_enabled'] == true 
      }
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance') { 
        values['ip_address'].none(type == 'PRIMARY') 
      }

  - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls
    title: Ensure Cloud SQL MySQL connections require SSL/TLS
    impact: 100
    variants:
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-all
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-hcl
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-plan
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-state
    docs:
      desc: |
        Requiring SSL/TLS for connections to Cloud SQL MySQL instances encrypts data in transit between the client and the database server. This prevents potential eavesdropping and man-in-the-middle attacks, protecting sensitive data from unauthorized access during transmission.

        It is strongly recommended to configure Cloud SQL instances to enforce SSL/TLS for all incoming connections to maintain data confidentiality and integrity. Note that enabling this setting requires clients to be configured correctly to use SSL/TLS, which might necessitate application updates.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: https://console.cloud.google.com/sql/instances
        2.  Click on the name of the MySQL instance you want to audit.
        3.  Select the **Connections** tab.
        4.  Go to the **Security** sub-tab.
        5.  Verify that the checkbox for **Allow only SSL connections** is checked.

        **Using the Google Cloud CLI**

        1.  Retrieve the configuration details for the instance:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```
        2.  Inspect the output and locate the `settings.ipConfiguration` section.
        3.  Ensure the value for `sslMode` is set to `ENCRYPTED_ONLY` and the value for `requireSsl` is set to `true`.

            Example relevant output snippet:
            ```yaml
            settings:
              ipConfiguration:
                sslMode: ENCRYPTED_ONLY
                requireSsl: true
                # ... other ipConfiguration settings
            ```
      remediation: |
        **Using the Google Cloud Console**

        1.  Access the Cloud SQL Instances overview page: https://console.cloud.google.com/sql/instances
        2.  Click the name of the target MySQL instance.
        3.  Navigate to the **Connections** tab, then the **Security** sub-tab.
        4.  Check the box labeled **Allow only SSL connections**.
        5.  Click **Save** to apply the change. *Note: This may trigger an instance restart.*

        **Using the Google Cloud CLI**

        1.  Enable the "Require SSL" setting for the instance:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --require-ssl
            ```
            *Note: This command may cause the instance to restart.*
        2.  Confirm the change:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format='value(settings.ipConfiguration.requireSsl)'
            ```
            The output should be `True`.

        **Using Terraform**

        Ensure the `require_ssl` attribute within the `ip_configuration` block is set to `true`:

        ```hcl
        resource "google_sql_database_instance" "default" {
          name             = "my-mysql-instance"
          database_version = "MYSQL_8_0"
          region           = "us-central1"

          settings {
            tier = "db-f1-micro"
            ip_configuration {
              ipv4_enabled = true
              # Set require_ssl to true
              require_ssl  = true
              ssl_mode     = "ENCRYPTED_ONLY"
            }
          }
        }
        ```

        **Prevention:**

        Always configure new Cloud SQL MySQL instances with the "Allow only SSL connections" option enabled during creation via the Console, CLI (`--require-ssl` flag), or Terraform (`require_ssl = true`). Regularly audit instances to ensure compliance.
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(maintenanceVersion.contains('MYSQL')) { 
        settings.ipConfiguration { 
          sslMode == 'ENCRYPTED_ONLY'
        } 
      }
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance') { 
        blocks { 
          blocks.where(attributes['ssl_mode'] != null) { 
            _.attributes['ssl_mode'].value == 'ENCRYPTED_ONLY'
          } 
        } 
      }
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance') { 
        change.after['settings'].first['ip_configuration'].first['ssl_mode'] == 'ENCRYPTED_ONLY'
      }
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance') { 
        values['settings'].first['ip_configuration'].first['ssl_mode'] == 'ENCRYPTED_ONLY' 
      }

  - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled
    title: Ensure 'skip_show_database' Database Flag for Cloud SQL MySQL Instances is enabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-all
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-hcl
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-plan
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        The 'skip_show_database' flag enhances security by restricting the use of the `SHOW DATABASES` command. When enabled ('on'), only users explicitly granted the `SHOW DATABASES` privilege can execute the command, and they will see all databases. If disabled ('off'), any user can run `SHOW DATABASES`, but they will only see databases for which they possess the `SHOW DATABASES` privilege or other specific privileges. Enabling this flag helps prevent users from discovering the existence of databases they shouldn't access. This setting applies specifically to Cloud SQL for MySQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a MySQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `skip_show_database` flag is listed and its value is set to `on`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each MySQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="skip_show_database")|.value'
            ```
            Ensure the output for each MySQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(settings.databaseFlags['skip_show_database'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target MySQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `skip_show_database` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific MySQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags skip_show_database=on
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags skip_show_database=on,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "mysql_instance" {
          name             = "my-mysql-instance"
          database_version = "MYSQL_8_0"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "skip_show_database"
              value = "on"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(
        settings.databaseFlags['skip_show_database'] == 'on'
      )
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('MYSQL')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'skip_show_database') { 
            arguments['value'] == 'on'
          } 
        }
      }
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')) {
        change.after['settings'].first['database_flags'].where(name == 'skip_show_database') {
          value == 'on'
        }
      }
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')) { 
        values['settings'].first['database_flags'].where(name == 'skip_show_database') {
         value == 'on' 
        } 
      }

  - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled
    title: Ensure the 'local_infile' Database Flag for Cloud SQL MySQL Instance is disabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-all
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-hcl
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-plan
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        The `local_infile` database flag dictates whether the server permits clients to load data using the `LOAD DATA LOCAL INFILE` statement. Enabling this feature (setting it to `on`) can introduce security vulnerabilities, as a compromised client or a malicious server could potentially access local files on the machine running the client or server, respectively. To mitigate this risk, it is strongly recommended to disable this flag by setting it to `off`. This recommendation applies specifically to Cloud SQL for MySQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a MySQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `local_infile` flag is listed and its value is set to `off`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each MySQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="local_infile")|.value'
            ```
            Ensure the output for each MySQL instance is `"off"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(settings.databaseFlags['local_infile'] == 'off')"
           ```
           Verify the flag value is `off` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target MySQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `local_infile` from the dropdown and set its value to `off`. If the flag exists but is `on`, change its value to `off`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific MySQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags local_infile=off
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags local_infile=off,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "mysql_instance" {
          name             = "my-mysql-instance"
          database_version = "MYSQL_8_0"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "local_infile"
              value = "off"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(
        settings.databaseFlags['local_infile'] == 'off'
      )
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('MYSQL')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'local_infile') { 
            arguments['value'] == 'off' 
          } 
        }
      }
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')) {
        change.after['settings'].first['database_flags'].where(name == 'local_infile') { 
          value == 'off'
        }
      }
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')) {
        values['settings'].first['database_flags'].where(name == 'local_infile') { 
          value == 'off' 
        }
      }

  - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose
    title: Ensure the 'log_error_verbosity' Database Flag for Cloud SQL PostgreSQL Instance Is Set to 'DEFAULT' or 'verbose'
    impact: 70
    variants:
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-all
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-hcl
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-plan
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-state
    docs:
      desc: |
        **Rationale:**

        The `log_error_verbosity` flag in PostgreSQL controls the level of detail included in server log messages for errors. Possible settings include `TERSE` (minimal details), `DEFAULT` (standard details), and `VERBOSE` (includes SQLSTATE codes, source file, function name, and line number). Logging provides essential information for troubleshooting and security analysis. Setting this flag to `DEFAULT` or `VERBOSE` ensures sufficient detail is captured without being overly sparse. Setting it to `TERSE` might omit crucial context needed for effective analysis. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_error_verbosity` flag is listed and its value is set to `DEFAULT` or `VERBOSE`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            # This command shows the value, verify it's "DEFAULT" or "VERBOSE"
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_error_verbosity")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"DEFAULT"` or `"VERBOSE"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings { databaseFlags['log_error_verbosity'] == 'verbose' })"
           ```
           Verify the flag value is `DEFAULT` or `VERBOSE` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target PostgreSQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `log_error_verbosity` from the dropdown and set its value to `DEFAULT` or `VERBOSE`. If the flag exists but is set to `TERSE`, change its value.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific PostgreSQL instance (choose `DEFAULT` or `VERBOSE`):
        ```bash
        # Example using DEFAULT
        gcloud sql instances patch INSTANCE_NAME --database-flags log_error_verbosity=DEFAULT

        # Example using VERBOSE
        gcloud sql instances patch INSTANCE_NAME --database-flags log_error_verbosity=VERBOSE
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_error_verbosity=DEFAULT,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting (choose `DEFAULT` or `VERBOSE`):
        ```hcl
        resource "google_sql_database_instance" "postgres_instance" {
          name             = "my-postgres-instance"
          database_version = "POSTGRES_15"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "log_error_verbosity"
              # Choose either "DEFAULT" or "VERBOSE"
              value = "DEFAULT"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(
        settings {
          databaseFlags['log_error_verbosity'] == 'verbose'
        }
      )
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'log_error_verbosity') { 
            arguments['value'] == 'verbose' 
          } 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')) {
        change.after['settings'].first['database_flags'].where(name == 'log_error_verbosity') {
          value.upcase == 'verbose'
        }
      }
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')) {
        values['settings'].first['database_flags'].where(name == 'log_error_verbosity') {
          value == 'verbose'
        }
      }

  - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled
    title: Ensure 'log_connections' Database Flag for Cloud SQL PostgreSQL Instances is enabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-all
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-hcl
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-plan
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        By default, PostgreSQL does not log connection attempts. Enabling the `log_connections` flag (setting it to `on`) configures the server to record each attempted connection and successful client authentication. This logging is valuable for security monitoring, allowing administrators to identify unusual connection patterns or potential unauthorized access attempts, and for troubleshooting connectivity issues. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_connections` flag is listed and its value is set to `on`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_connections")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings.databaseFlags['log_connections'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target PostgreSQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `log_connections` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific PostgreSQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags log_connections=on
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_connections=on,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "postgres_instance" {
          name             = "my-postgres-instance"
          database_version = "POSTGRES_15"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "log_connections"
              value = "on"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(
        settings.databaseFlags['log_connections'] == 'on'
      )
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'log_connections') { 
            arguments['value'] == 'on' 
          } 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')) {
        change.after['settings'].first['database_flags'].where(name == 'log_connections') { 
          value == 'on'
        }
      }
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')) {
        values['settings'].first['database_flags'].where(name == 'log_connections') { 
          value == 'on' 
        }
      }

  - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled
    title: Ensure 'log_disconnections' Database Flag for Cloud SQL PostgreSQL Instances is enabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-all
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-hcl
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-plan
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        PostgreSQL, by default, does not log the end of user sessions or their duration. Enabling the `log_disconnections` flag (setting it to `on`) causes the server to log this information. This data complements the information provided by `log_connections` and is crucial for auditing user activity, identifying long-running or unusual sessions, and troubleshooting connection-related issues. It provides a complete picture of the connection lifecycle. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_disconnections` flag is listed and its value is set to `on`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_disconnections")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings.databaseFlags['log_disconnections'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target PostgreSQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `log_disconnections` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific PostgreSQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags log_disconnections=on
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_disconnections=on,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "postgres_instance" {
          name             = "my-postgres-instance"
          database_version = "POSTGRES_15"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "log_disconnections"
              value = "on"
            }
            # Include other settings and flags as needed, e.g., log_connections
            database_flags {
              name  = "log_connections"
              value = "on"
            }
          }
        }
        ```
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(
        settings.databaseFlags['log_disconnections'] == 'on'
      )
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'log_disconnections') { 
            arguments['value'] == 'on' 
          } 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')) {
        change.after['settings'].first['database_flags'].where(name == 'log_disconnections') { 
          value == 'on' 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')) {
        values['settings'].first['database_flags'].where(name == 'log_disconnections') { 
          value == 'on' 
        }
      }

  - uid: mondoo-gcp-security-compute-instances-no-public-ip
    title: Ensure public IP addresses are not assigned to VM instances
    impact: 75
    variants:
      - uid: gcp-compute-instances-no-public-ip-single
      - uid: gcp-compute-instances-no-public-ip-terraform-hcl
      - uid: gcp-compute-instances-no-public-ip-terraform-plan
      - uid: gcp-compute-instances-no-public-ip-terraform-state
    docs:
      desc: |
        Virtual machine (VM) instances within Google Cloud Compute Engine should not be configured with public, external IP addresses.

        **Rationale:**

        Assigning public IP addresses directly to VM instances increases their exposure to potential attacks from the internet. To minimize this attack surface, instances should ideally be placed behind services like Google Cloud Load Balancing, which manage external access securely and efficiently, reducing direct exposure of the VM.

        **Impact:**

        Disabling the external IP address on a Compute instance might disrupt applications or services hosted on that instance if they rely on direct public internet connectivity. Careful planning is required before making this change.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Review the list of VM instances. For each instance, verify that the `External IP` column shows `None`.

        **From Google Cloud CLI**

        Execute the following command to list instances and their network configurations:
        ```
        gcloud compute instances list --format=json
        ```

        1. Examine the JSON output for each instance. Ensure that the `networkInterfaces` array does not contain an `accessConfigs` section. The presence of `accessConfigs` indicates an external IP configuration. Note that the `natIP` field within `accessConfigs` might only appear for running instances or stopped instances with a static external IP. Stopped instances configured for ephemeral IPs might not show `natIP`.

        Example indicating an external IP:
        ```json
        "networkInterfaces": [
         {
          "accessConfigs": [
           {
            "kind": "compute#accessConfig",
            "name": "External NAT",
            "networkTier": "PREMIUM",
            "type": "ONE_TO_ONE_NAT"
           }
          ],
          ...
         }
        ]
        ```

        **Exception:**
        Instances managed by Google Kubernetes Engine (GKE) often require external IPs for node pools or specific services. These instances typically have names starting with `gke-` and possess the label `goog-gke-node`. They should be excluded from this check as their network configuration is managed by GKE.
      remediation: |
        **From Google Cloud Console**

        1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click the name of the target instance to open its details page.
        3. Click the `Edit` button at the top.
        4. Scroll down to the `Network interfaces` section.
        5. For the relevant network interface, click the pencil icon to edit it.
        6. Set the `External IP` dropdown menu to `None`.
        7. Click `Done` to close the network interface settings.
        8. Click `Save` at the bottom of the page to apply the changes.

        **From Google Cloud CLI**

        1. First, identify the name of the access configuration associated with the external IP. Describe the instance:
        ```
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(networkInterfaces[].accessConfigs)'
        ```
        Look for the `name` field within the `accessConfigs` array (e.g., `External NAT`).

        2. Delete the identified access configuration using its name:
        ```
        gcloud compute instances delete-access-config INSTANCE_NAME --zone=ZONE --access-config-name="ACCESS_CONFIG_NAME"
        ```
        Replace `INSTANCE_NAME`, `ZONE`, and `ACCESS_CONFIG_NAME` with the appropriate values.

        **Prevention:**
        Utilize the Organization Policy `constraints/compute.vmExternalIpAccess` to restrict or deny the assignment of external IP addresses to VMs across your organization or specific folders/projects. Configure this policy at: [https://console.cloud.google.com/orgpolicies/compute-vmExternalIpAccess](https://console.cloud.google.com/orgpolicies/compute-vmExternalIpAccess)
  - uid: gcp-compute-instances-confidential-vm-enabled-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
      gcp.compute.instance.machineType.name == /n2d-/
    mql: |
      gcp.compute.instance.confidentialInstanceConfig['enabled'] == true
  - uid: gcp-compute-instances-confidential-vm-enabled-terraform-hcl
    filters: |
      asset.platform == "terraform-hcl"
    mql: |
      terraform.resources {
        blocks.where(type == "confidential_instance_config") {
          attributes['enable_confidential_compute'].value == true
        }
      }
  - uid: gcp-compute-instances-confidential-vm-enabled-terraform-plan
    filters: |
      asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance") {
        change.after['confidential_instance_config'] {
          enable_confidential_compute == true
        }
      }
  - uid: gcp-compute-instances-confidential-vm-enabled-terraform-state
    filters: |
      asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "google_compute_instance") {
        values['confidential_instance_config'] {
          _['enable_confidential_compute'] == true
        }
      }

  - uid: mondoo-gcp-security-compute-instances-no-default-service-account
    title: Ensure the default service account is not used on VM instances
    impact: 80
    variants:
      - uid: gcp-compute-instances-no-default-service-account-single
      - uid: gcp-compute-instances-no-default-service-account-terraform-plan
      - uid: gcp-compute-instances-no-default-service-account-terraform-state
    docs:
      desc: |
        VM instances should be configured to use dedicated service accounts instead of the default Compute Engine service account.

        **Rationale:**

        The default Compute Engine service account (`[PROJECT_NUMBER]-compute@developer.gserviceaccount.com`) is automatically granted the highly permissive `Editor` role at the project level. If a VM using this default account is compromised, an attacker could potentially gain broad access to modify resources across the project. To adhere to the principle of least privilege and limit the potential impact of a compromised instance, create and assign custom service accounts with only the necessary permissions required by the VM.

        **Impact:**

        Changing the service account associated with a VM requires stopping and starting the instance. Ensure applications running on the VM can tolerate this brief downtime. Using a custom service account with insufficient permissions might cause applications on the VM to fail if they rely on APIs they can no longer access.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click on the name of an instance to view its details.
        3. Locate the `API and identity management` section.
        4. Verify that the `Service account` listed is **not** the default Compute Engine service account (which follows the pattern `[PROJECT_NUMBER]-compute@developer.gserviceaccount.com`). Repeat for all relevant instances.

        **From Google Cloud CLI**

        1. List instances along with their associated service account emails:
        ```
        gcloud compute instances list --format='value(name,serviceAccounts[0].email)'
        ```
        Alternatively, for more detailed JSON output:
        ```
        gcloud compute instances list --format=json
        ```
        Then inspect the `serviceAccounts` array for each instance.

        2. For each instance, ensure the listed service account email does not match the default pattern `[PROJECT_NUMBER]-compute@developer.gserviceaccount.com`. You can find your project number using `gcloud projects describe $(gcloud config get-value project) --format='value(projectNumber)'`.

        **Exception:**
        VMs managed by GKE (names starting with `gke-`, labeled `goog-gke-node`) often use specific service accounts managed by GKE itself, which might include the default service account in some configurations. These should typically be excluded from this check unless specific organizational policies dictate otherwise.
      remediation: |
        **From Google Cloud Console**

        1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click the name of the instance you want to modify.
        3. Click the `STOP` button at the top and confirm. Wait for the instance to stop completely.
        4. Once stopped, click the `EDIT` button.
        5. Scroll down to the `API and identity management` section.
        6. In the `Service account` dropdown, select a suitable custom service account. If needed, create a new service account with appropriate permissions first via the `IAM & Admin` -> `Service Accounts` page.
        7. Click `Save` at the bottom.
        8. Click the `START / RESUME` button at the top to restart the instance.

        **From Google Cloud CLI**

        1. Stop the target instance:
        ```
        gcloud compute instances stop INSTANCE_NAME --zone=ZONE
        ```
        2. Assign the desired custom service account:
        ```
        gcloud compute instances set-service-account INSTANCE_NAME --zone=ZONE --service-account=CUSTOM_SERVICE_ACCOUNT_EMAIL
        ```
        Replace `INSTANCE_NAME`, `ZONE`, and `CUSTOM_SERVICE_ACCOUNT_EMAIL` with the correct values.
        3. Start the instance again:
        ```
        gcloud compute instances start INSTANCE_NAME --zone=ZONE
        ```
  - uid: gcp-compute-instances-no-default-service-account-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      compute_engine_default_service_account_email = gcp.project.number + '-compute@developer.gserviceaccount.com'
      gcp.compute.instance {
        serviceAccounts.none(
          email == compute_engine_default_service_account_email
        )
      }
  - uid: gcp-compute-instances-no-default-service-account-terraform-plan
    filters: |
      asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance") {
        change.after['service_account'] {
          email == /$-compute@developer.gserviceaccount.com/
        }
      }
  - uid: gcp-compute-instances-no-default-service-account-terraform-state
    filters: |
      asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "google_compute_instance") {
        values['service_account'] {
          _['email'] == /$-compute@developer.gserviceaccount.com/
        }
      }

  - uid: mondoo-gcp-security-compute-instances-block-project-wide-ssh-keys
    title: Ensure Block Project-Wide SSH Keys Is Enabled for VM Instances
    impact: 80
    variants:
      - uid: gcp-compute-instances-block-project-wide-ssh-keys-single
      - uid: gcp-compute-instances-block-project-wide-ssh-keys-terraform-hcl
      - uid: gcp-compute-instances-block-project-wide-ssh-keys-terraform-plan
      - uid: gcp-compute-instances-block-project-wide-ssh-keys-terraform-state
    docs:
      desc: |
        Configure VM instances to block project-wide SSH keys, favoring instance-specific keys for access.

        **Rationale:**

        Project-wide SSH keys, managed in the project's metadata, allow users associated with those keys to access *all* VM instances within that project by default. While convenient, this creates a significant security risk: if a project-wide key is compromised, all instances become vulnerable. Enabling the "Block Project-Wide SSH Keys" setting on an instance forces the use of instance-level SSH keys (stored in instance metadata), thereby limiting the scope of access and reducing the blast radius if a key is compromised.

        **Impact:**

        Enabling this setting will prevent users from connecting to the instance using project-wide SSH keys via tools like standard SSH clients. Access using the `gcloud compute ssh` command or the SSH-in-browser feature usually remains unaffected, as these tools often manage temporary or instance-specific keys. Users needing direct SSH access with third-party clients will require instance-specific SSH keys to be added to the VM's metadata.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click on the name of the instance you want to check.
        3. Scroll down to the `SSH Keys` section.
        4. Verify that the checkbox labeled `Block project-wide SSH keys` is checked. Repeat for all relevant instances.

        **From Google Cloud CLI**

        1. Retrieve the metadata for the instance, specifically looking for the `block-project-ssh-keys` key:
        ```
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(metadata.items)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Examine the output. Ensure there is an item where `key` is `block-project-ssh-keys` and its corresponding `value` is `true`. If the key is missing or set to `false`, project-wide keys are not blocked.

        Alternatively, list all instances and filter for the metadata key:
        ```
        gcloud compute instances list --format='table(name,zone,metadata.items.filter(key:block-project-ssh-keys).extract(value))'
        ```
        Instances showing `True` in the last column have the setting enabled.
      remediation: |
        **From Google Cloud Console**

        1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click the name of the instance to modify.
        3. Click the `Edit` button at the top.
        4. Scroll down to the `SSH Keys` section (it might be under `Security and access` or a similar heading).
        5. Check the box for `Block project-wide SSH keys`.
        6. Click `Save` at the bottom of the page.
        7. Repeat these steps for all instances where project-wide keys should be blocked.

        **From Google Cloud CLI**

        Enable the setting by adding or updating the instance metadata:
        ```
        gcloud compute instances add-metadata INSTANCE_NAME --zone=ZONE --metadata block-project-ssh-keys=true
        ```
        Replace `INSTANCE_NAME` and `ZONE` with the appropriate values. This command will either add the key if it doesn't exist or update its value to `true` if it does.
  - uid: gcp-compute-instances-block-project-wide-ssh-keys-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      gcp.compute.instance {
        metadata['block-project-ssh-keys'] == true
      }
  - uid: gcp-compute-instances-block-project-wide-ssh-keys-terraform-hcl
    filters: |
      asset.platform == "terraform-hcl"
    mql: |
      terraform.resources.where(attributes['metadata'] != null) {
        attributes['metadata'].value['block-project-ssh-keys'] == true
      }
  - uid: gcp-compute-instances-block-project-wide-ssh-keys-terraform-plan
    filters: |
      asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance") {
        change.after['metadata']['block-project-ssh-keys'] == true
      }
  - uid: gcp-compute-instances-block-project-wide-ssh-keys-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == "google_compute_instance") {
        values['metadata'] {
          _['block-project-ssh-keys'] == true
        }
      }

  - uid: mondoo-gcp-security-compute-instances-confidential-vm-service-enabled
    title: Ensure Confidential VM Service is enabled for all VM instances
    impact: 75
    variants:
      - uid: gcp-compute-instances-confidential-vm-service-enabled-single
      - uid: gcp-compute-instances-confidential-vm-service-enabled-terraform-hcl
      - uid: gcp-compute-instances-confidential-vm-service-enabled-terraform-plan
      - uid: gcp-compute-instances-confidential-vm-service-enabled-terraform-state
    docs:
      desc: |
        Enable the Confidential VM service for applicable Compute Engine VM instances to enhance data security during processing.

        **Rationale:**

        While Google Cloud encrypts data at rest and in transit, Confidential Computing adds a layer of protection by encrypting data while it's actively being processed in memory (data-in-use). Confidential VMs utilize hardware-based security features (like AMD SEV) to create an isolated environment where data remains encrypted even during computation. This helps protect sensitive data from potential access by the cloud provider or vulnerabilities in the host system, using hardware-generated, instance-specific keys that are not exportable.

        **Impact:**

        - Confidential VMs currently support specific machine types (primarily N2D series) and may have limitations, such as the lack of support for live migration, meaning instances will be terminated during host maintenance events.
        - Enabling this feature might incur additional costs compared to standard VMs. Refer to the official GCP pricing documentation for details: [https://cloud.google.com/compute/confidential-vm/pricing](https://cloud.google.com/compute/confidential-vm/pricing).
      audit: |
        Note: Confidential Computing is primarily available on N2D machine types. Check current documentation for supported types: [https://cloud.google.com/compute/docs/machine-types#n2d_machine_types](https://cloud.google.com/compute/docs/machine-types#n2d_machine_types)

        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click on the name of an N2D instance (or other supported type) to view its details.
        3. Look for the `Confidential VM service` status indicator within the instance properties.
        4. Ensure the status shows as `Enabled` or `On`.

        **From Google Cloud CLI**

        1. List instances and check their confidential computing configuration:
        ```
        gcloud compute instances list --format='json(name,machineType,confidentialInstanceConfig)'
        ```
        2. For instances using a supported machine type (e.g., containing "n2d-"), verify that the `confidentialInstanceConfig` section exists and the `enableConfidentialCompute` field is set to `true`.

        Example output for a configured instance:
        ```json
        {
         "confidentialInstanceConfig": {
          "enableConfidentialCompute": true
         },
         "machineType": "...",
         "name": "..."
        }
        ```
      remediation: |
        The Confidential VM service can only be activated when creating a new VM instance. It cannot be enabled on an existing instance.

        **From Google Cloud Console**

        1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click `CREATE INSTANCE`.
        3. Configure the instance settings (name, region, zone).
        4. Select a supported machine type from the N2D series (or other applicable types) under `Machine configuration`.
        5. Scroll down to the `Confidential VM service` section.
        6. Check the box labeled `Enable the Confidential Computing service on this VM instance`. Note that this usually requires setting the `On host maintenance` policy to `Terminate VM instance`.
        7. Configure other settings as needed (boot disk, networking, etc.).
        8. Click `Create`.

        **From Google Cloud CLI**

        Use the `--confidential-compute` flag during instance creation. You must also set the maintenance policy to `TERMINATE`.
        ```
        gcloud compute instances create INSTANCE_NAME \
         --zone=ZONE \
         --machine-type=N2D_MACHINE_TYPE \
         --confidential-compute \
         --maintenance-policy=TERMINATE \
         # Add other necessary flags like --image-project, --image, --network, etc.
        ```
        Replace placeholders like `INSTANCE_NAME`, `ZONE`, and `N2D_MACHINE_TYPE` with appropriate values.
  - uid: gcp-compute-instances-confidential-vm-service-enabled-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
      gcp.compute.instance.machineType.name == /n2d-/
    mql: |
      gcp.compute.instance {
        confidentialInstanceConfig['serviceEnabled'] == true
      }
  - uid: gcp-compute-instances-confidential-vm-service-enabled-terraform-hcl
    filters: |
      asset.platform == "terraform-hcl"
    mql: |
      terraform.resources {
        blocks.where(type == 'confidential_instance_config') {
          attributes['enable_confidential_compute'].value == true
        }
      }
  - uid: gcp-compute-instances-confidential-vm-service-enabled-terraform-plan
    filters: |
      asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance") {
        change.after['boot_disk'] {
          _['initialize_params'].all(
            _['enable_confidential_compute'] == true
          )
        }
      }
  - uid: gcp-compute-instances-confidential-vm-service-enabled-terraform-state
    filters: |
      asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "google_compute_instance") {
        values['confidential_instance_config'] {
          _['enable_confidential_compute'] == true
        }
      }

  - uid: mondoo-gcp-security-compute-instances-secure-boot-enabled
    title: Ensure Secure Boot is enabled for all VM instances
    impact: 90
    variants:
      - uid: gcp-compute-instances-secure-boot-enabled-single
      - uid: gcp-compute-instances-secure-boot-enabled-terraform-hcl
      - uid: gcp-compute-instances-secure-boot-enabled-terraform-plan
      - uid: gcp-compute-instances-secure-boot-enabled-terraform-state
    docs:
      desc: |
        Enable Secure Boot, a feature of Shielded VMs, on Compute Engine instances to enhance platform security and integrity.

        **Rationale:**

        Shielded VMs provide verifiable integrity for Compute Engine instances, offering protection against boot-level and kernel-level malware and rootkits. Secure Boot is a critical component of this protection. It ensures that the instance boots only with software (like the bootloader and OS kernel) that is digitally signed and trusted. By verifying these signatures against trusted certificates stored in the UEFI firmware, Secure Boot prevents malicious software from taking control during the boot process. Google manages the signing and verification of the firmware itself, establishing a strong root of trust.

        **Impact:**

        Secure Boot requires using a Shielded VM-compatible OS image. Enabling Secure Boot might prevent systems with custom, unsigned kernel drivers or boot components from booting successfully. Ensure all necessary components are properly signed before enabling this feature.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click on the name of the instance you want to check.
        3. In the `VM instance details` page, locate the `Shielded VM` section.
        4. Verify that the `Secure Boot` toggle or status indicator shows `Enabled` or `On`.

        **From Google Cloud CLI**

        1. Describe the instance and check its Shielded VM configuration:
        ```
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(shieldedInstanceConfig)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Examine the output. Ensure the `shieldedInstanceConfig` object exists and the `enableSecureBoot` field is set to `true`. If `shieldedInstanceConfig` is absent or `enableSecureBoot` is `false`, the feature is not enabled.
      remediation: |
        Secure Boot can only be enabled on instances using an OS image that supports Shielded VM features.

        **From Google Cloud Console**

        1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click the name of the instance to modify.
        3. If the instance is running, click `STOP` and confirm. Wait for it to stop.
        4. Click `EDIT`.
        5. Scroll to the `Shielded VM` section.
        6. Check the box or toggle the switch to enable `Secure Boot`. Enabling Secure Boot typically requires vTPM and Integrity Monitoring to also be enabled or automatically enabled alongside it.
        7. Click `Save`.
        8. Click `START / RESUME` to restart the instance.

        **From Google Cloud CLI**

        Ensure the instance uses a compatible image. You can list public Shielded VM images:
        ```
        gcloud compute images list --project gce-uefi-images --no-standard-images --filter="shieldedVmFeatures:(SECURE_BOOT)"
        ```

        1. Stop the instance if it is running:
        ```
        gcloud compute instances stop INSTANCE_NAME --zone=ZONE
        ```
        2. Update the instance to enable Secure Boot (this command implicitly enables vTPM and Integrity Monitoring as well):
        ```
        gcloud compute instances update INSTANCE_NAME --zone=ZONE --shielded-vm-secure-boot
        ```
        3. Start the instance:
        ```
        gcloud compute instances start INSTANCE_NAME --zone=ZONE
        ```

        **Prevention:**
        Enforce the use of Shielded VMs for all new instances by configuring the `constraints/compute.requireShieldedVm` Organization Policy. Manage this policy at: [https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm](https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm). See documentation for details: [https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint](https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint).
  - uid: gcp-compute-instances-secure-boot-enabled-single
    filters: |
      asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance {
        enableSecureBoot == true
      }
  - uid: gcp-compute-instances-secure-boot-enabled-terraform-hcl
    filters: |
      asset.platform == "terraform-hcl"
    mql: |
      terraform.resources {
        blocks.where(type == 'shielded_instance_config') {
          attributes['enable_secure_boot'].value == true
        }
      }
  - uid: gcp-compute-instances-secure-boot-enabled-terraform-plan
    filters: |
      asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance") {
        change.after['shielded_instance_config'] {
          _['enable_secure_boot'] == true
        }
      }
  - uid: gcp-compute-instances-secure-boot-enabled-terraform-state
    filters: |
      asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "google_compute_instance") {
        values['shielded_instance_config'] {
          _['enable_secure_boot'] == true
        }
      }

  - uid: mondoo-gcp-security-compute-instances-vtpm-enabled
    title: Ensure vTPM is enabled for all VM instances
    impact: 90
    variants:
      - uid: gcp-compute-instances-vtpm-enabled-single
      - uid: gcp-compute-instances-vtpm-enabled-terraform-hcl
      - uid: gcp-compute-instances-vtpm-enabled-terraform-plan
      - uid: gcp-compute-instances-vtpm-enabled-terraform-state
    docs:
      desc: |
        Enable the virtual Trusted Platform Module (vTPM), a feature of Shielded VMs, on Compute Engine instances to support Measured Boot and enhance integrity verification.

        **Rationale:**

        Shielded VMs leverage several security controls to harden instances against threats. The vTPM is a virtualized version of a hardware TPM, providing secure cryptographic functions and secure storage. Its primary role within Shielded VM is to enable Measured Boot. During Measured Boot, the vTPM securely records cryptographic measurements (hashes) of boot components (firmware, bootloader, kernel). This creates a verifiable record of the boot process, forming an integrity policy baseline essential for Integrity Monitoring.

        **Impact:**

        Enabling vTPM is necessary for using Shielded VM's Measured Boot and Integrity Monitoring capabilities. It generally has negligible impact on instance performance and compatibility, but it requires using a Shielded VM-compatible OS image.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click on the name of the instance you want to check.
        3. In the `VM instance details` page, find the `Shielded VM` section.
        4. Verify that the `vTPM` toggle or status indicator shows `Enabled` or `On`.

        **From Google Cloud CLI**

        1. Describe the instance and check its Shielded VM configuration:
        ```
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(shieldedInstanceConfig)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Look at the output. Ensure the `shieldedInstanceConfig` object is present and the `enableVtpm` field is set to `true`. If `shieldedInstanceConfig` is missing or `enableVtpm` is `false`, the feature is disabled.
      remediation: |
        vTPM can only be enabled on instances using an OS image that supports Shielded VM features.

        **From Google Cloud Console**

        1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click the name of the instance to modify.
        3. If the instance is running, click `STOP` and confirm. Wait for it to stop completely.
        4. Click `EDIT`.
        5. Scroll down to the `Shielded VM` section.
        6. Check the box or toggle the switch to enable `vTPM`.
        7. Click `Save`.
        8. Click `START / RESUME` to restart the instance.

        **From Google Cloud CLI**

        Ensure the instance uses a compatible image. You can list public Shielded VM images:
        ```
        gcloud compute images list --project gce-uefi-images --no-standard-images --filter="shieldedVmFeatures:(VTPM)"
        ```

        1. Stop the instance if it is running:
        ```
        gcloud compute instances stop INSTANCE_NAME --zone=ZONE
        ```
        2. Update the instance to enable vTPM:
        ```
        gcloud compute instances update INSTANCE_NAME --zone=ZONE --shielded-vtpm
        ```
        Note: This command specifically targets vTPM. If Secure Boot or Integrity Monitoring are desired, they might need separate flags (`--shielded-vm-secure-boot`, `--shielded-vm-integrity-monitoring`) or enabling them might implicitly enable vTPM.
        3. Start the instance:
        ```
        gcloud compute instances start INSTANCE_NAME --zone=ZONE
        ```

        **Prevention:**
        Mandate the use of Shielded VMs (which includes vTPM) for new instances via the `constraints/compute.requireShieldedVm` Organization Policy. Configure it at: [https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm](https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm). Refer to documentation: [https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint](https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint).
  - uid: gcp-compute-instances-vtpm-enabled-single
    filters: |
      asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance {
        enableVtpm == true
      }
  - uid: gcp-compute-instances-vtpm-enabled-terraform-hcl
    filters: |
      asset.platform == "terraform-hcl"
    mql: |
      terraform.resources {
        blocks.where(type == 'shielded_instance_config') {
          attributes['enable_vtpm'].value == true
        }
      }
  - uid: gcp-compute-instances-vtpm-enabled-terraform-plan
    filters: |
      asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance") {
        change.after['shielded_instance_config'] {
          _['enable_vtpm'] == true
        }
      }
  - uid: gcp-compute-instances-vtpm-enabled-terraform-state
    filters: |
      asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "google_compute_instance") {
        values['shielded_instance_config'] {
          _['enable_vtpm'] == true
        }
      }

  - uid: mondoo-gcp-security-compute-instances-integrity-monitoring-enabled
    title: Ensure Integrity Monitoring is enabled for all VM instances
    impact: 90
    variants:
      - uid: gcp-compute-instances-integrity-monitoring-enabled-single
      - uid: gcp-compute-instances-integrity-monitoring-enabled-terraform-hcl
      - uid: gcp-compute-instances-integrity-monitoring-enabled-terraform-plan
      - uid: gcp-compute-instances-integrity-monitoring-enabled-terraform-state
    docs:
      desc: |
        Enable Integrity Monitoring, a feature of Shielded VMs, on Compute Engine instances to detect potentially malicious modifications to the boot sequence.

        **Rationale:**

        Shielded VMs provide enhanced security for instances. Integrity Monitoring, a key component, leverages the measurements taken by the vTPM during Measured Boot. It compares the boot measurements of the current boot process against a known good baseline established during a previous boot. If discrepancies are detected, it indicates that the bootloader, kernel, or other critical boot components may have been tampered with, potentially by rootkits or boot-level malware. This allows administrators to identify compromised instances and take appropriate action.

        **Impact:**

        Integrity Monitoring requires both a Shielded VM-compatible OS image and vTPM to be enabled. It provides valuable security insights by logging integrity check results to Cloud Logging, with minimal overhead on instance performance.
      audit: |
        **From Google Cloud Console**

        1. Navigate to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click on the name of the instance you want to check.
        3. In the `VM instance details` page, locate the `Shielded VM` section.
        4. Verify that the `Integrity Monitoring` toggle or status indicator shows `Enabled` or `On`.

        **From Google Cloud CLI**

        1. Describe the instance and check its Shielded VM configuration:
        ```
        gcloud compute instances describe INSTANCE_NAME --zone=ZONE --format='json(shieldedInstanceConfig)'
        ```
        Replace `INSTANCE_NAME` and `ZONE` accordingly.

        2. Examine the output. Ensure the `shieldedInstanceConfig` object exists and the `enableIntegrityMonitoring` field is set to `true`. If `shieldedInstanceConfig` is absent or `enableIntegrityMonitoring` is `false`, the feature is not enabled.
      remediation: |
        Integrity Monitoring requires an instance using an OS image that supports Shielded VM features, and vTPM must also be enabled.

        **From Google Cloud Console**

        1. Go to the `VM instances` page: [https://console.cloud.google.com/compute/instances](https://console.cloud.google.com/compute/instances).
        2. Click the name of the instance to modify.
        3. If the instance is running, click `STOP` and confirm. Wait for it to stop completely.
        4. Click `EDIT`.
        5. Scroll down to the `Shielded VM` section.
        6. Ensure `vTPM` is enabled.
        7. Check the box or toggle the switch to enable `Integrity Monitoring`.
        8. Click `Save`.
        9. Click `START / RESUME` to restart the instance.

        **From Google Cloud CLI**

        Ensure the instance uses a compatible image and has vTPM enabled. You can list public Shielded VM images:
        ```
        gcloud compute images list --project gce-uefi-images --no-standard-images --filter="shieldedVmFeatures:(INTEGRITY_MONITORING)"
        ```

        1. Stop the instance if it is running:
        ```
        gcloud compute instances stop INSTANCE_NAME --zone=ZONE
        ```
        2. Update the instance to enable Integrity Monitoring (this command implicitly enables vTPM as well):
        ```
        gcloud compute instances update INSTANCE_NAME --zone=ZONE --shielded-vm-integrity-monitoring
        ```
        3. Start the instance:
        ```
        gcloud compute instances start INSTANCE_NAME --zone=ZONE
        ```

        **Prevention:**
        Enforce the use of Shielded VMs (which includes Integrity Monitoring when enabled) for new instances using the `constraints/compute.requireShieldedVm` Organization Policy. Configure this at: [https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm](https://console.cloud.google.com/iam-admin/orgpolicies/compute-requireShieldedVm). See documentation: [https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint](https://cloud.google.com/security/shielded-cloud/shielded-vm#organization-policy-constraint).
  - uid: gcp-compute-instances-integrity-monitoring-enabled-single
    filters: |
      asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance {
        enableIntegrityMonitoring == true
      }
  - uid: gcp-compute-instances-integrity-monitoring-enabled-terraform-hcl
    filters: |
      asset.platform == "terraform-hcl"
    mql: |
      terraform.resources {
        blocks.where(type == 'shielded_instance_config') {
          attributes['enable_integrity_monitoring'].value == true
        }
      }
  - uid: gcp-compute-instances-integrity-monitoring-enabled-terraform-plan
    filters: |
      asset.platform == "terraform-plan"
    mql: |
      terraform.plan.resourceChanges.where(type == "google_compute_instance") {
        change.after['shielded_instance_config'] {
          _['enable_integrity_monitoring'] == true
        }
      }
  - uid: gcp-compute-instances-integrity-monitoring-enabled-terraform-state
    filters: |
      asset.platform == "terraform-state"
    mql: |
      terraform.state.resources.where(type == "google_compute_instance") {
        values['shielded_instance_config'] {
          _['enable_integrity_monitoring'] == true
        }
      }
