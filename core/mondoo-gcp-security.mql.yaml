# Copyright (c) Mondoo, Inc.
# SPDX-License-Identifier: BUSL-1.1

policies:
  - uid: mondoo-gcp-security
    name: Mondoo Google Cloud (GCP) Security
    version: 1.1.0
    license: BUSL-1.1
    tags:
      mondoo.com/category: security
      mondoo.com/platform: gcp,cloud
    authors:
      - name: Mondoo, Inc
        email: hello@mondoo.com
    docs:
      desc: |
        The Mondoo Google Cloud (GCP) Security policy is designed to identify critical misconfigurations that could leave your Google Cloud infrastructure vulnerable to attackers. This policy helps organizations detect and remediate security risks before they can be exploited, reducing the likelihood of unauthorized access, data breaches, privilege escalation, and operational disruptions.

        ## Join the community!

        Our goal is to build policies that are simple to deploy, accurate, and actionable. This policy is open-source and we welcome contributions from the community, whether it's adding new checks, refining existing ones, or providing feedback. If you have suggestions to improve this policy, visit our [cnspec-policies repository](https://github.com/mondoohq/cnspec-policies).
    groups:
      - title: GCP Project
        filters: |
          asset.family.contains('google')
          asset.runtime == 'gcp'
        checks:
          - uid: mondoo-gcp-security-block-project-wide-ssh-keys-enabled-vm-instances
          - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible
          - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled
          - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account
          - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api
          - uid: mondoo-gcp-security-oslogin-enabled-project
    scoring_system: highest impact
queries:
  - uid: mondoo-gcp-security-instances-are-not-configured-use-default-service-account
    title: Ensure that instances are not configured to use the default service account
    impact: 95
    variants:
      - uid: gcp-compute-instances-configured-use-default-service-account-single
      - uid: gcp-compute-instances-configured-use-default-service-account-terraform-hcl
      - uid: gcp-compute-instances-configured-use-default-service-account-terraform-plan
      - uid: gcp-compute-instances-configured-use-default-service-account-terraform-state
    docs:
      desc: |
        New projects that have enabled the Compute Engine API have a Compute Engine default service account, which contains the following email pattern:

        ```bash
        -compute@developer.gserviceaccount.com
        ```

        The Compute Engine default service account is created with the IAM basic Editor role, but you can modify your service account's roles to control the service account's access to Google APIs.

        You can disable or delete this service account from your project, but doing so might cause any applications that depend on the service account's credentials to fail. If you accidentally delete the Compute Engine default service account, you can try to recover the account within 30 days. For more information, see Creating and managing service accounts.

        It is recommended that you do not configure instances with the default service account. Instead, create a user account using the principle of least privilege.
      audit: |
        __cnquery run__

        To audit your Google Cloud Project with `cnquery run`:

        1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

        2. Run this query:

          ```mql
          cnquery run gcp project <project-id> -c "gcp.compute.instances.where( name != /^gke/ ) {id name serviceAccounts.where( email == /^.*compute@developer\.gserviceaccount\.com$/ )}"
          ```

        __cnquery shell__

        To audit your Google Cloud Project with `cnquery shell`:

        1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

        2. Launch `cnquery shell`:

          ```bash
          cnquery run gcp project <project-id>
          ```

        3. Run this query:

          ```mql
          gcp.compute.instances.where( name != /^gke/ ) {id name serviceAccounts.where(email == /^.*compute@developer\.gserviceaccount\.com$/ )}
          ```
      remediation: |
        ### Terraform

        To provision or update a compute instance with a custom service account:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          service_account {
            email  = "example@example.com"
            scopes = ['user-email", "compute-ro", "storage-ro']
          }
        }
        ```

        ### Google Cloud Console

        To change the policy using the GCP Console, follow these steps:

        1. Log in to the GCP Console at https://console.cloud.google.com.
        2. Select the Organization and Project where the instance you want to update is running.
        3. Navigate to **Compute Engine**.
        4. Select the compute instance that you want to update.
        5. If the instance is not stopped, select **Stop**. Wait for the instance to stop.
        6. Select **Edit**.
        7. Scroll down to the Service Account section.
        8. Select a different service account.
        9. Select **Save**.
        10. Select **START**.

        ### gcloud cli

        To update the service account using the `gcloud` cli:

        1. Stop the instance:

          ```bash
          gcloud compute instances stop INSTANCE_NAME
          ```

        2. Update the instance:

          ```bash
          gcloud compute instances set-service-account INSTANCE_NAME --serviceaccount=SERVICE_ACCOUNT --scopes [SCOPE1, SCOPE2...]
          ```

        3. Restart the instance:

          ```bash
          gcloud compute instances start INSTANCE_NAME
          ```
  - uid: gcp-compute-instances-configured-use-default-service-account-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
        gcp.compute.instance.serviceAccounts.none(
          email == /^.*compute@developer\.gserviceaccount\.com$/
        )
  - uid: gcp-compute-instances-configured-use-default-service-account-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_compute_instance').any(
        blocks.where(type == 'service_account').one(type == 'service_account')
      )
  - uid: gcp-compute-instances-configured-use-default-service-account-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance').none(
        change.after.contains(/^.*compute@developer\.gserviceaccount\.com$/)
      )
  - uid: gcp-compute-instances-configured-use-default-service-account-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance'){ 
        values.service_account.contains(/^.*compute@developer\.gserviceaccount\.com$/) 
      }

  - uid: mondoo-gcp-security-instances-not-configured-with-default-service-account-full-access-cloud-api
    title: Ensure instances are not configured to use the default service account with full access to all Cloud APIs
    impact: 90
    variants:
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-single
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-hcl
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-plan
      - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-state
    docs:
      desc: |
        Google compute instances provisioned with full access to all cloud APIs pose a security risk to a GCP environment. Instances should instead be provisioned using a non-default service account, and limited permissions to cloud APIs using the principle of least privilege.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Run this query:

          ```mql
          cnquery run gcp project <project-id> -c "gcp.compute.instances.where( name != /^gke/ ) {id name serviceAccounts.where( email == /^.*compute@developer\.gserviceaccount\.com$/ ) {email scopes}}"
          ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Launch `cnquery shell`:

          ```bash
          cnquery shell gcp
          ```

         3. Run this query:

          ```mql
          gcp.compute.instances.where(name != /^gke/) {id name serviceAccounts.where(email == /^.*compute@developer\.gserviceaccount\.com$/) {email scopes}}
          ```
      remediation: |
        ### Terraform

        To provision or update a compute instance with Terraform:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          service_account {
            # Google recommends custom service accounts with cloud-platform scope and permissions granted via IAM Roles.
            email  = google_service_account.default.email
            scopes = ['cloud-platform']
          }
        }
        ```

        ### Google Cloud Console

        To change the policy using the Google Cloud Console:

        1. Log in to the GCP Console at https://console.cloud.google.com.
        2. Select the Organization and Project where the instance you want to update is running.
        3. Navigate to **Compute Engine**.
        4. Select the compute instance that you want to update.
        5. If the instance is not stopped, select **Stop**. Wait for the instance to stop.
        6. Select **Edit**.
        7. Scroll down to the Service Account section.
        8. Select a different service account or ensure Allow full access to all Cloud APIs is not selected.
        9. Select **Save**.
        10. Select **START**.

        ### gcloud cli

        To update the service account using the `gcloud` cli:

        1. Stop the instance:

          ```bash
          gcloud compute instances stop INSTANCE_NAME
          ```

        2. Update the instance:

          ```bash
          gcloud compute instances set-service-account INSTANCE_NAME --serviceaccount=SERVICE_ACCOUNT --scopes [SCOPE1, SCOPE2...]
          ```

        3. Restart the instance:

          ```bash
          gcloud compute instances start INSTANCE_NAME
          ```
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-single
    filters: |
      asset.platform == 'gcp-compute-instance'
      gcp.compute.instance.name != /^gke-/
    mql: |
      gcp.compute.instance.serviceAccounts.none(
        scopes == 'https://www.googleapis.com/auth/cloud-platform'
      )
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl' && terraform.plan.resourceChanges.contains(type == 'google_compute_instance')
    mql: |
      terraform.resources.where(nameLabel == 'google_compute_instance') { 
        blocks.where(type == 'service_account') { 
          arguments.scopes.none(_ == 'https://www.googleapis.com/auth/cloud-platform') 
        } 
      }
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-plan
    filters: |
      asset.platform == 'terraform-plan' && terraform.plan.resourceChanges.contains(type 'google_compute_instance')
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_compute_instance') { 
        change.after.service_account.map(scopes).first.none(_ == 'https://www.googleapis.com/auth/cloud-platform') 
      }
  - uid: gcp-compute-instances-configured-use-default-service-account-full-access-all-cloud-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance') { 
        values.service_account.map(scopes).first.where(_ == 'https://www.googleapis.com/auth/cloud-platform') 
      }

  - uid: mondoo-gcp-security-block-project-wide-ssh-keys-enabled-vm-instances
    title: Ensure "Block Project-wide SSH keys" is enabled for VM instances
    impact: 70
    variants:
      - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-single
      - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-terraform-state
    docs:
      desc: |
        Project-wide SSH keys can be used to login into all instances within a project. While using project-wide SSH keys eases SSH key management, if SSH keys are compromised, the potential security risk can impact all instances within a project.

        The recommended approach is to use instance-specific SSH keys instead of common/shared project-wide SSH keys.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Run this query:

          ```mql
          cnquery run gcp -c "gcp.compute.instances {id name metadata['block-project-ssh-keys'] }"
          ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Launch `cnquery shell`:

          ```bash
          cnquery shell gcp
          ```

         3. Run this query:

          ```mql
          gcp.compute.instances {id name metadata['block-project-ssh-keys'] }
          ```
      remediation: |
        ### Terraform

        To provision or update a compute instance with Terraform:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          metadata = {
            block-project-ssh-keys = true
          }
        }
        ```

        ### Google Cloud Console

        To change the policy using the GCP Console:

        1. Log in to the GCP Console at https://console.cloud.google.com.
        2. Select the organization/project where the instance(s) you want to update are running.
        3. Navigate to **Compute Engine**.
        4. Select the instance you want to update.
        5. Select **EDIT** in the toolbar.
        6. Under the **Security and access** section, select the **Block project-wide SSH keys** option.
        7. Select **SAVE**.

        Repeat these steps for each impacted Instance.

        ### gcloud cli

        To update an instance using the `gcloud` cli:

        1. Update the instance:

          ```bash
          gcloud compute instances add-metadata INSTANCE_NAME --metadata block-projectssh-keys=TRUE
          ```
  - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-single
    filters: asset.platform == 'gcp-compute-instance'
    mql: |
      gcp.compute.instance.metadata['block-project-ssh-keys'] == true
  - uid: gcp-compute-block-project-wide-ssh-keys-enabled-vm-instances-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance') { 
        values.metadata['block-project-ssh-keys'] == true 
      }

  - uid: mondoo-gcp-security-oslogin-enabled-project
    title: Ensure oslogin is enabled for compute instances
    impact: 70
    variants:
      - uid: gcp-compute-oslogin-enabled-project-single
      - uid: gcp-compute-oslogin-enabled-project-terraform-state
    docs:
      desc: |
        OS Login lets you use Compute Engine Identity and Access Management (IAM) roles to grant or revoke SSH access to your Linux instances. OS Login is an alternative to managing instance access by adding and removing SSH keys in metadata.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Run this query:

          ```mql
          cnquery run gcp project <project-id> -c "gcp.compute.instances {id name metadata['enable-oslogin'] == true}"
          ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

          ```bash
          gcloud config set project <project_id>
          ```

         2. Launch `cnquery shell`:

          ```bash
          cnquery shell gcp project <project-id>
          ```

         3. Run this query:

          ```mql
          gcp.compute.instances {id name metadata['enable-oslogin'] }
          ```
      remediation: |
        ### Terraform

        To configure OS Login for a project:

        ```hcl
        resource "google_compute_project_metadata" "default" {
          metadata = {
            enable-oslogin = "TRUE"
          }
        }
        ```

        To provision or update a compute instance with Terraform:

        ```hcl
        resource "google_compute_instance" "default" {
          name         = "secure-instance"
          machine_type = var.machine_type
          zone         = var.zone
          tags = ['terraform']

          metadata = {
            enable-oslogin = true
          }
        }
        ```

        ### Google Cloud Console

        To configure OS Login for a project via Google Cloud Console:

        1. In the Google Cloud console, go to the **Metadata** page.
        2. Select **EDIT**.
        3. Add a metadata entry, setting the key to `enable-oslogin` and the value to `TRUE`.
        4. Select **SAVE** to apply the changes.

        To configure OS Login for an existing instance:

        1. In the Google Cloud console, go to the **Compute Engine**.
        2. Select the name of the instance that you want to enable OS Login on.
        3. On the instance details page, select **EDIT**.
        4. Under **Custom metadata**, add a metadata entry, setting the key to `enable-oslogin` and the value to `TRUE`.
        5. Select **SAVE**.

        ### gcloud cli

        To update OS Login for a project using the `gcloud` cli:

          ```bash
          gcloud compute project-info add-metadata --metadata enable-oslogin=TRUE
          ```

        To update OS Login for an existing instance using the `gcloud` cli:

          ```bash
          gcloud compute instances add-metadata INSTANCE_NAME --metadata enable-oslogin=TRUE
          ```
  - uid: gcp-compute-oslogin-enabled-project-single
    filters: asset.platform 'gcp-compute-instance'
    mql:
      gcp.compute.instance.metadata['enable-oslogin'] == true
  - uid: gcp-compute-oslogin-enabled-project-terraform-state
    filters: |
      asset.platform == 'terraform-state' && terraform.state.resources.contains(type == 'google_compute_instance')
    mql: |
      terraform.state.resources.where(type == 'google_compute_instance') { 
        values.metadata['enable-oslogin'] == true
      }

  - uid: mondoo-gcp-security-cloud-storage-bucket-not-anonymously-publicly-accessible
    title: Ensure that Cloud Storage buckets are not anonymously or publicly accessible
    impact: 90
    variants:
      - uid: gcp-storage-cloud-storage-bucket-anonymously-publicly-accessible-single
    docs:
      desc: |
        Public access prevention protects Cloud Storage buckets and objects from being accidentally exposed to the public. When you enforce public access prevention, no one can make data in applicable buckets public through IAM policies or ACLs.
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Run this query:

           ```mql
           cnquery run gcp -c "gcloud.storage.buckets { iamPolicy { members {*} } } "
           ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Launch `cnquery shell`:

           ```bash
           cnquery shell gcp
           ```

         3. Run this query:

           ```mql
           gcloud.storage.buckets { iamPolicy { members {*} } }
           ```
      remediation: |
        ### Terraform

        To update public access configuration using Terraform, ensure `allUsers` and `allAuthenticatedUsers` are not set:

        ```hcl
        resource "google_storage_bucket_iam_binding" "binding" {
          bucket = google_storage_bucket.default.name
          role = "roles/storage.admin"
          members = [
            "user:jane@example.com",
          ]
        }
        ```

        ```hcl
        resource "google_storage_bucket_iam_member" "member" {
          bucket = google_storage_bucket.default.name
          role = "roles/storage.admin"
          member = "user:jane@example.com"
        }
        ```

        ### Google Cloud Console
        1. In the Google Cloud console, go to the **Cloud Storage Bucket** page.
        2. For the bucket you want to enforce public access prevention on, select the more actions menu.
        3. Select **Edit access** from the drop-down menu.
        4. In the Public access card, select **Prevent public access** to enforce public access prevention.
        5. Select **Confirm**.

        ### gcloud cli

        Update an existing storage bucket with the `gcloud` cli:

        ```bash
        gcloud storage buckets update gs://BUCKET_NAME --no-pap
        ```
  - uid: gcp-storage-cloud-storage-bucket-anonymously-publicly-accessible-single
    filters: asset.platform == 'gcp-storage-bucket'
    mql: |
      gcp.storage.bucket.iamPolicy.all(members.none(_ == 'allUsers'))
      gcp.storage.bucket.iamPolicy.all(members.none(_ == 'allAuthenticatedUsers'))

  - uid: mondoo-gcp-security-cloud-storage-buckets-have-uniform-bucket-level-access-enabled
    title: Ensure that Cloud Storage buckets have uniform bucket-level access enabled
    impact: 60
    variants:
      - uid: gcp-storage-cloud-storage-buckets-uniform-bucket-level-access-enabled-single
    docs:
      desc: |
        Cloud Storage offers two systems for granting users permission to access your buckets and objects: IAM and Access Control Lists (ACLs). These systems act in parallel - in order for a user to access a Cloud Storage resource, only one of the systems needs to grant the user permission. IAM is used throughout Google Cloud and allows you to grant a variety of permissions at the bucket and project levels. ACLs are used only by Cloud Storage and have limited permission options, but they allow you to grant permissions on a per-object basis.

        It is recommended to enable uniform bucket-level access on Cloud Storage buckets. Uniform bucket-level access is used to unify and simplify how you grant access to your Cloud Storage resources. Cloud Storage offers two systems that act in parallel to grant users permission to access buckets and objects:
      audit: |
        __cnquery run__

         To audit your Google Cloud Project with `cnquery run`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Run this query:

           ```bash
           cnquery run gcp -c "gcloud.storage.buckets { iamConfiguration['UniformBucketLevelAccess']['Enabled'] }"
           ```

         __cnquery shell__

         To audit your Google Cloud Project with `cnquery shell`:

         1. Ensure the `gcloud` cli is configured to the GCP project:

           ```bash
           gcloud config set project <project_id>
           ```

         2. Launch `cnquery shell`:

           ```bash
           cnquery shell gcp
           ```

         3. Run this query:

           ```mql
           gcloud.storage.buckets { iamConfiguration['UniformBucketLevelAccess']['Enabled'] }
           ```
      remediation: |
        ### Terraform

        ```hcl
        resource "google_storage_bucket" "example" {
          name     = "test-bucket"
          bucket_policy_only = true
          uniform_bucket_level_access = true
        }
        ```

        ### Google Cloud Console

        1. In the Google Cloud console, go to the **Cloud Storage Buckets** page.
        2. In the list of buckets, select the name of the desired bucket.
        3. Select the **Permissions** tab near the top of the page.
        4. In the text box named **Access Control**, select the **Switch to** link. Note that the text box disappears 90 days after you enable uniform bucket-level access.
        5. In the pop-up menu that appears, select **Fine-grained**.
        6. Select **Save**.

        ### gcloud cli

        ```bash
        gsutil uniformbucketlevelaccess set STATE gs://BUCKET_NAME
        ```
  - uid: gcp-storage-cloud-storage-buckets-uniform-bucket-level-access-enabled-single
    filters: asset.platform 'gcp-storage-bucket'
    mql: gcp.storage.bucket.iamConfiguration.UniformBucketLevelAccess.enabled == true

  - uid: mondoo-gcp-security-cloud-sql-mysql-instances-not-publicly-exposed
    title: Ensure Cloud SQL MySQL instances are not publicly exposed
    impact: 100
    variants:
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-all
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-hcl
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-plan
      - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-state
    docs:
      desc: |
        Assigning public IP addresses to Cloud SQL MySQL instances expands the potential attack surface, making databases accessible from the public internet and increasing security risks.

        The recommended practice is to configure instances exclusively with private IP addresses. This enhances security by isolating the database within your VPC network and can reduce latency for internal applications. Be aware that removing a public IP will disrupt existing connections that depend on it; establish and test private connectivity paths before making the change.
      audit: |
        **Using the Google Cloud Console**

          1. Navigate to the Cloud SQL Instances page within the Google Cloud Console: https://console.cloud.google.com/sql/instances
          2. Review each MySQL instance listed. For every primary (non-replica) Second Generation instance, examine its networking details to confirm that a Private IP address is assigned and that no Public IP address is present.

        ** Using the Google Cloud CLI **

          1. Obtain a list of all your Cloud SQL instances:

            ```bash
            gcloud sql instances list
            ```

          2. For each instance identified as `backendType: SECOND_GEN` and `instanceType: CLOUD_SQL_INSTANCE` (primary instance), retrieve its full configuration details. Read replicas (`instanceType: READ_REPLICA_INSTANCE`) inherit network settings, and First Generation instances do not support private IPs, so they can be skipped for this check.

            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```

          3. Inspect the `ipAddresses` section in the output for the instance. Verify that an entry exists with `type: PRIVATE`. Crucially, ensure there is no entry with `type: PRIMARY`, as this indicates a public IP address. While an instance can technically possess both during transitions, the secure state is having only the `PRIVATE` type assigned.
      remediation: |
        **Using the Google Cloud Console**

        1.  Access the Cloud SQL Instances overview page in the Google Cloud Console: https://console.cloud.google.com/sql/instances
        2.  Click on the name of the target instance to view its configuration details.
        3.  Navigate to the **Connections** settings tab.
        4.  Under the **Networking** section, locate and uncheck the box labeled **Public IP**.
        5.  Confirm the modification by clicking the **Save** button.

        **Using the Google Cloud CLI**

        1.  Modify the target instance to remove its public IP address and ensure it's associated with a VPC network for private IP access. Replace `INSTANCE_NAME` with the actual instance name and `VPC_NETWORK_NAME` with the desired VPC network name:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --network=VPC_NETWORK_NAME --no-assign-ip
            ```
            *Note: If the instance is already associated with the correct VPC network for private IP, you might only need the `--no-assign-ip` flag.*
        2.  Verify that the public IP address has been removed by inspecting the instance's configuration:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```
            Check the `ipAddresses` section in the output to confirm the absence of an entry with `type: PRIMARY`.

        **Prevention:**

        To proactively enforce that new Cloud SQL instances are not created with public IP addresses, implement the `Restrict Public IP access on Cloud SQL instances` Organization Policy. You can configure this policy at: https://console.cloud.google.com/iam-admin/orgpolicies/sql-restrictPublicIp
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(maintenanceVersion.contains('MYSQL')) {
        ipAddresses.all(
          _.type != "PRIMARY"
        )
      }
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance') { 
        blocks { 
          blocks.where(attributes['ipv4_enabled'] != null) { 
            _.attributes['ipv4_enabled'].value == true 
          } 
        } 
      }
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance') { 
        change.after['settings'].first['ip_configuration'].first['ipv4_enabled'] == true 
      }
  - uid: gcp-cloud-sql-mysql-instances-not-publicly-exposed-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance') { 
        values['ip_address'].none(type == 'PRIMARY') 
      }

  - uid: mondoo-gcp-security-cloud-sql-mysql-connections-require-ssl-tls
    title: Ensure Cloud SQL MySQL connections require SSL/TLS
    impact: 100
    variants:
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-all
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-hcl
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-plan
      - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-state
    docs:
      desc: |
        Requiring SSL/TLS for connections to Cloud SQL MySQL instances encrypts data in transit between the client and the database server. This prevents potential eavesdropping and man-in-the-middle attacks, protecting sensitive data from unauthorized access during transmission.

        It is strongly recommended to configure Cloud SQL instances to enforce SSL/TLS for all incoming connections to maintain data confidentiality and integrity. Note that enabling this setting requires clients to be configured correctly to use SSL/TLS, which might necessitate application updates.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: https://console.cloud.google.com/sql/instances
        2.  Click on the name of the MySQL instance you want to audit.
        3.  Select the **Connections** tab.
        4.  Go to the **Security** sub-tab.
        5.  Verify that the checkbox for **Allow only SSL connections** is checked.

        **Using the Google Cloud CLI**

        1.  Retrieve the configuration details for the instance:
            ```bash
            gcloud sql instances describe INSTANCE_NAME
            ```
        2.  Inspect the output and locate the `settings.ipConfiguration` section.
        3.  Ensure the value for `sslMode` is set to `ENCRYPTED_ONLY` and the value for `requireSsl` is set to `true`.

            Example relevant output snippet:
            ```yaml
            settings:
              ipConfiguration:
                sslMode: ENCRYPTED_ONLY
                requireSsl: true
                # ... other ipConfiguration settings
            ```
      remediation: |
        **Using the Google Cloud Console**

        1.  Access the Cloud SQL Instances overview page: https://console.cloud.google.com/sql/instances
        2.  Click the name of the target MySQL instance.
        3.  Navigate to the **Connections** tab, then the **Security** sub-tab.
        4.  Check the box labeled **Allow only SSL connections**.
        5.  Click **Save** to apply the change. *Note: This may trigger an instance restart.*

        **Using the Google Cloud CLI**

        1.  Enable the "Require SSL" setting for the instance:
            ```bash
            gcloud sql instances patch INSTANCE_NAME --require-ssl
            ```
            *Note: This command may cause the instance to restart.*
        2.  Confirm the change:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format='value(settings.ipConfiguration.requireSsl)'
            ```
            The output should be `True`.

        **Using Terraform**

        Ensure the `require_ssl` attribute within the `ip_configuration` block is set to `true`:

        ```hcl
        resource "google_sql_database_instance" "default" {
          name             = "my-mysql-instance"
          database_version = "MYSQL_8_0"
          region           = "us-central1"

          settings {
            tier = "db-f1-micro"
            ip_configuration {
              ipv4_enabled = true
              # Set require_ssl to true
              require_ssl  = true
              ssl_mode     = "ENCRYPTED_ONLY"
            }
          }
        }
        ```

        **Prevention:**

        Always configure new Cloud SQL MySQL instances with the "Allow only SSL connections" option enabled during creation via the Console, CLI (`--require-ssl` flag), or Terraform (`require_ssl = true`). Regularly audit instances to ensure compliance.
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(maintenanceVersion.contains('MYSQL')) { 
        settings.ipConfiguration { 
          sslMode == 'ENCRYPTED_ONLY'
        } 
      }
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance') { 
        blocks { 
          blocks.where(attributes['ssl_mode'] != null) { 
            _.attributes['ssl_mode'].value == 'ENCRYPTED_ONLY'
          } 
        } 
      }
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance') { 
        change.after['settings'].first['ip_configuration'].first['ssl_mode'] == 'ENCRYPTED_ONLY'
      }
  - uid: gcp-cloud-sql-mysql-instances-require-ssl-tls-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance') { 
        values['settings'].first['ip_configuration'].first['ssl_mode'] == 'ENCRYPTED_ONLY' 
      }

  - uid: mondoo-gcp-security-cloud-sql-mysql-skip-show-database-enabled
    title: Ensure 'skip_show_database' Database Flag for Cloud SQL MySQL Instances is enabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-all
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-hcl
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-plan
      - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        The 'skip_show_database' flag enhances security by restricting the use of the `SHOW DATABASES` command. When enabled ('on'), only users explicitly granted the `SHOW DATABASES` privilege can execute the command, and they will see all databases. If disabled ('off'), any user can run `SHOW DATABASES`, but they will only see databases for which they possess the `SHOW DATABASES` privilege or other specific privileges. Enabling this flag helps prevent users from discovering the existence of databases they shouldn't access. This setting applies specifically to Cloud SQL for MySQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a MySQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `skip_show_database` flag is listed and its value is set to `on`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each MySQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="skip_show_database")|.value'
            ```
            Ensure the output for each MySQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(settings.databaseFlags['skip_show_database'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target MySQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `skip_show_database` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific MySQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags skip_show_database=on
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags skip_show_database=on,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "mysql_instance" {
          name             = "my-mysql-instance"
          database_version = "MYSQL_8_0"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "skip_show_database"
              value = "on"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(
        settings.databaseFlags['skip_show_database'] == 'on'
      )
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('MYSQL')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'skip_show_database') { 
            arguments['value'] == 'on'
          } 
        }
      }
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')) {
        change.after['settings'].first['database_flags'].where(name == 'skip_show_database') {
          value == 'on'
        }
      }
  - uid: gcp-cloud-sql-mysql-skip-show-database-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')) { 
        values['settings'].first['database_flags'].where(name == 'skip_show_database') {
         value == 'on' 
        } 
      }

  - uid: mondoo-gcp-security-cloud-sql-mysql-local-infile-disabled
    title: Ensure the 'local_infile' Database Flag for Cloud SQL MySQL Instance is disabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-all
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-hcl
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-plan
      - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        The `local_infile` database flag dictates whether the server permits clients to load data using the `LOAD DATA LOCAL INFILE` statement. Enabling this feature (setting it to `on`) can introduce security vulnerabilities, as a compromised client or a malicious server could potentially access local files on the machine running the client or server, respectively. To mitigate this risk, it is strongly recommended to disable this flag by setting it to `off`. This recommendation applies specifically to Cloud SQL for MySQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a MySQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `local_infile` flag is listed and its value is set to `off`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each MySQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="local_infile")|.value'
            ```
            Ensure the output for each MySQL instance is `"off"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(settings.databaseFlags['local_infile'] == 'off')"
           ```
           Verify the flag value is `off` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target MySQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `local_infile` from the dropdown and set its value to `off`. If the flag exists but is `on`, change its value to `off`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific MySQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags local_infile=off
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags local_infile=off,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "mysql_instance" {
          name             = "my-mysql-instance"
          database_version = "MYSQL_8_0"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "local_infile"
              value = "off"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^MYSQL_/).all(
        settings.databaseFlags['local_infile'] == 'off'
      )
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('MYSQL')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'local_infile') { 
            arguments['value'] == 'off' 
          } 
        }
      }
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('MYSQL')) {
        change.after['settings'].first['database_flags'].where(name == 'local_infile') { 
          value == 'off'
        }
      }
  - uid: gcp-cloud-sql-mysql-local-infile-disabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('MYSQL')) {
        values['settings'].first['database_flags'].where(name == 'local_infile') { 
          value == 'off' 
        }
      }

  - uid: mondoo-gcp-security-cloud-sql-postgres-log-error-verbosity-default-verbose
    title: Ensure the 'log_error_verbosity' Database Flag for Cloud SQL PostgreSQL Instance Is Set to 'DEFAULT' or 'verbose'
    impact: 70
    variants:
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-all
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-hcl
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-plan
      - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-state
    docs:
      desc: |
        **Rationale:**

        The `log_error_verbosity` flag in PostgreSQL controls the level of detail included in server log messages for errors. Possible settings include `TERSE` (minimal details), `DEFAULT` (standard details), and `VERBOSE` (includes SQLSTATE codes, source file, function name, and line number). Logging provides essential information for troubleshooting and security analysis. Setting this flag to `DEFAULT` or `VERBOSE` ensures sufficient detail is captured without being overly sparse. Setting it to `TERSE` might omit crucial context needed for effective analysis. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_error_verbosity` flag is listed and its value is set to `DEFAULT` or `VERBOSE`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            # This command shows the value, verify it's "DEFAULT" or "VERBOSE"
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_error_verbosity")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"DEFAULT"` or `"VERBOSE"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings { databaseFlags['log_error_verbosity'] == 'verbose' })"
           ```
           Verify the flag value is `DEFAULT` or `VERBOSE` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target PostgreSQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `log_error_verbosity` from the dropdown and set its value to `DEFAULT` or `VERBOSE`. If the flag exists but is set to `TERSE`, change its value.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific PostgreSQL instance (choose `DEFAULT` or `VERBOSE`):
        ```bash
        # Example using DEFAULT
        gcloud sql instances patch INSTANCE_NAME --database-flags log_error_verbosity=DEFAULT

        # Example using VERBOSE
        gcloud sql instances patch INSTANCE_NAME --database-flags log_error_verbosity=VERBOSE
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_error_verbosity=DEFAULT,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting (choose `DEFAULT` or `VERBOSE`):
        ```hcl
        resource "google_sql_database_instance" "postgres_instance" {
          name             = "my-postgres-instance"
          database_version = "POSTGRES_15"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "log_error_verbosity"
              # Choose either "DEFAULT" or "VERBOSE"
              value = "DEFAULT"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(
        settings {
          databaseFlags['log_error_verbosity'] == 'verbose'
        }
      )
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'log_error_verbosity') { 
            arguments['value'] == 'verbose' 
          } 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')) {
        change.after['settings'].first['database_flags'].where(name == 'log_error_verbosity') {
          value.upcase == 'verbose'
        }
      }
  - uid: gcp-cloud-sql-postgres-log-error-verbosity-default-verbose-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')) {
        values['settings'].first['database_flags'].where(name == 'log_error_verbosity') {
          value == 'verbose'
        }
      }

  - uid: mondoo-gcp-security-cloud-sql-postgres-log-connections-enabled
    title: Ensure 'log_connections' Database Flag for Cloud SQL PostgreSQL Instances is enabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-all
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-hcl
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-plan
      - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        By default, PostgreSQL does not log connection attempts. Enabling the `log_connections` flag (setting it to `on`) configures the server to record each attempted connection and successful client authentication. This logging is valuable for security monitoring, allowing administrators to identify unusual connection patterns or potential unauthorized access attempts, and for troubleshooting connectivity issues. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_connections` flag is listed and its value is set to `on`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_connections")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings.databaseFlags['log_connections'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target PostgreSQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `log_connections` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific PostgreSQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags log_connections=on
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_connections=on,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "postgres_instance" {
          name             = "my-postgres-instance"
          database_version = "POSTGRES_15"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "log_connections"
              value = "on"
            }
            # Include other settings and flags as needed
          }
        }
        ```
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(
        settings.databaseFlags['log_connections'] == 'on'
      )
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'log_connections') { 
            arguments['value'] == 'on' 
          } 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')) {
        change.after['settings'].first['database_flags'].where(name == 'log_connections') { 
          value == 'on'
        }
      }
  - uid: gcp-cloud-sql-postgres-log-connections-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')) {
        values['settings'].first['database_flags'].where(name == 'log_connections') { 
          value == 'on' 
        }
      }

  - uid: mondoo-gcp-security-cloud-sql-postgres-log-disconnections-enabled
    title: Ensure 'log_disconnections' Database Flag for Cloud SQL PostgreSQL Instances is enabled
    impact: 70
    variants:
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-all
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-hcl
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-plan
      - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-state
    docs:
      desc: |
        **Rationale:**

        PostgreSQL, by default, does not log the end of user sessions or their duration. Enabling the `log_disconnections` flag (setting it to `on`) causes the server to log this information. This data complements the information provided by `log_connections` and is crucial for auditing user activity, identifying long-running or unusual sessions, and troubleshooting connection-related issues. It provides a complete picture of the connection lifecycle. This recommendation applies specifically to Cloud SQL for PostgreSQL instances.
      audit: |
        **Using the Google Cloud Console**

        1.  Navigate to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select a PostgreSQL instance to view its details.
        3.  In the **Configuration** section, find the **Database flags** area.
        4.  Verify that the `log_disconnections` flag is listed and its value is set to `on`.

        **Using the Google Cloud CLI**

        1.  List your Cloud SQL instances:
            ```bash
            gcloud sql instances list
            ```
        2.  For each PostgreSQL instance, check the flag's value:
            ```bash
            gcloud sql instances describe INSTANCE_NAME --format=json | jq '.settings.databaseFlags[] | select(.name=="log_disconnections")|.value'
            ```
            Ensure the output for each PostgreSQL instance is `"on"`.

        **Using cnquery**

        1. Ensure the `gcloud` CLI is configured for your project:
           ```bash
           gcloud config set project <project_id>
           ```
        2. Run the query:
           ```mql
           cnquery run gcp project <project-id> -c "gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(settings.databaseFlags['log_disconnections'] == 'on')"
           ```
           Verify the flag value is `on` for all relevant instances.
      remediation: |
        **Using the Google Cloud Console**

        1.  Go to the Cloud SQL Instances page: [https://console.cloud.google.com/sql/instances](https://console.cloud.google.com/sql/instances).
        2.  Select the target PostgreSQL instance.
        3.  Click **Edit**.
        4.  Scroll down to the **Flags** section.
        5.  If the flag isn't present, click **Add item**.
        6.  Choose `log_disconnections` from the dropdown and set its value to `on`. If the flag exists but is `off`, change its value to `on`.
        7.  Click **Save**. Review the **Flags** section on the instance overview page to confirm.

        **Using the Google Cloud CLI**

        Update the flag for a specific PostgreSQL instance:
        ```bash
        gcloud sql instances patch INSTANCE_NAME --database-flags log_disconnections=on
        ```
        *Note: This command overwrites all existing flags. To preserve other flags, you must include them in the `--database-flags` argument (e.g., `--database-flags log_disconnections=on,other_flag=value`).*

        **Using Terraform**

        Ensure the `database_flags` block within your `google_sql_database_instance` resource includes the setting:
        ```hcl
        resource "google_sql_database_instance" "postgres_instance" {
          name             = "my-postgres-instance"
          database_version = "POSTGRES_15"
          region           = "us-central1"
          settings {
            tier = "db-f1-micro"
            database_flags {
              name  = "log_disconnections"
              value = "on"
            }
            # Include other settings and flags as needed, e.g., log_connections
            database_flags {
              name  = "log_connections"
              value = "on"
            }
          }
        }
        ```
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-all
    filters: |
      asset.platform == 'gcp' || asset.platform == 'gcp-project'
    mql: |
      gcp.project.sql.instances.where(databaseInstalledVersion == /^POSTGRES_/).all(
        settings.databaseFlags['log_disconnections'] == 'on'
      )
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-hcl
    filters: |
      asset.platform == 'terraform-hcl'
    mql: |
      terraform.resources.where(nameLabel == 'google_sql_database_instance' && arguments['database_version'].contains('POSTGRES')) { 
        blocks.where(type == 'settings') { 
          blocks.where(type == 'database_flags').where(attributes['name'].value == 'log_disconnections') { 
            arguments['value'] == 'on' 
          } 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-plan
    filters: |
      asset.platform == 'terraform-plan'
    mql: |
      terraform.plan.resourceChanges.where(type == 'google_sql_database_instance' && change.after.database_version.contains('POSTGRES')) {
        change.after['settings'].first['database_flags'].where(name == 'log_disconnections') { 
          value == 'on' 
        }
      }
  - uid: gcp-cloud-sql-postgres-log-disconnections-enabled-terraform-state
    filters: |
      asset.platform == 'terraform-state'
    mql: |
      terraform.state.resources.where(type == 'google_sql_database_instance' && values.database_version.contains('POSTGRES')) {
        values['settings'].first['database_flags'].where(name == 'log_disconnections') { 
          value == 'on' 
        }
      }
